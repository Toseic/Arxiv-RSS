<?xml version="1.0" ?>
<rss>
 <channel>
  <title>arxiv-rss</title>
  <link></link>
  <description></description>
  <docs></docs>
  <language>en-us</language>
  <lastBuildDate>Thu, 09 Oct 2025 04:15:40 </lastBuildDate>
  <managingEditor></managingEditor>
  <pubDate>Thu, 09 Oct 2025 04:15:40 </pubDate>
  <item>
   <title>Beyond Static Knowledge Messengers: Towards Adaptive, Fair, and Scalable Federated Learning for Medical AI</title>
   <link>https://arxiv.org/abs/2510.06259</link>
   <description>Medical AI faces challenges in privacy-preserving collaborative learning while ensuring fairness across heterogeneous healthcare institutions. Current federated learning approaches suffer from static architectures, slow convergence (45-73 rounds), fairness gaps marginalizing smaller institutions, and scalability constraints (15-client limit). We propose Adaptive Fair Federated Learning (AFFL) through three innovations: (1) Adaptive Knowledge Messengers dynamically scaling capacity based on heterogeneity and task complexity, (2) Fairness-Aware Distillation using influence-weighted aggregation, and (3) Curriculum-Guided Acceleration reducing rounds by 60-70%. Our theoretical analysis provides convergence guarantees with epsilon-fairness bounds, achieving O(T^{-1/2}) + O(H_max/T^{3/4}) rates. Projected results show 55-75% communication reduction, 56-68% fairness improvement, 34-46% energy savings, and 100+ institution support. The framework enables multi-modal integration across imaging, genomics, EHR, and sensor data while maintaining HIPAA/GDPR compliance. We propose MedFedBench benchmark suite for standardized evaluation across six healthcare dimensions: convergence efficiency, institutional fairness, privacy preservation, multi-modal integration, scalability, and clinical deployment readiness. Economic projections indicate 400-800% ROI for rural hospitals and 15-25% performance gains for academic centers. This work presents a seven-question research agenda, 24-month implementation roadmap, and pathways toward democratizing healthcare AI.</description>
   <guid>oai:arXiv.org:2510.06259v1</guid>
   <category>cs.CY</category>
   <category>cs.LG</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</rights>
   <creator>Jahidul Arafat, Fariha Tasmin, Sanjaya Poudel, Ahsan Habib Tareq, Iftekhar Haider</creator>
  </item>
  <item>
   <title>Layerwise Federated Learning for Heterogeneous Quantum Clients using Quorus</title>
   <link>https://arxiv.org/abs/2510.06228</link>
   <description>Quantum machine learning (QML) holds the promise to solve classically intractable problems, but, as critical data can be fragmented across private clients, there is a need for distributed QML in a quantum federated learning (QFL) format. However, the quantum computers that different clients have access to can be error-prone and have heterogeneous error properties, requiring them to run circuits of different depths. We propose a novel solution to this QFL problem, Quorus, that utilizes a layerwise loss function for effective training of varying-depth quantum models, which allows clients to choose models for high-fidelity output based on their individual capacity. Quorus also presents various model designs based on client needs that optimize for shot budget, qubit count, midcircuit measurement, and optimization space. Our simulation and real-hardware results show the promise of Quorus: it increases the magnitude of gradients of higher depth clients and improves testing accuracy by 12.4% on average over the state-of-the-art.</description>
   <guid>oai:arXiv.org:2510.06228v1</guid>
   <category>quant-ph</category>
   <category>cs.DC</category>
   <category>cs.ET</category>
   <category>cs.LG</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Jason Han, Nicholas S. DiBrita, Daniel Leeds, Jianqiang Li, Jason Ludmir, Tirthak Patel</creator>
  </item>
  <item>
   <title>Cluster Paths: Navigating Interpretability in Neural Networks</title>
   <link>https://arxiv.org/abs/2510.06541</link>
   <description>While modern deep neural networks achieve impressive performance in vision tasks, they remain opaque in their decision processes, risking unwarranted trust, undetected biases and unexpected failures. We propose cluster paths, a post-hoc interpretability method that clusters activations at selected layers and represents each input as its sequence of cluster IDs. To assess these cluster paths, we introduce four metrics: path complexity (cognitive load), weighted-path purity (class alignment), decision-alignment faithfulness (predictive fidelity), and path agreement (stability under perturbations). In a spurious-cue CIFAR-10 experiment, cluster paths identify color-based shortcuts and collapse when the cue is removed. On a five-class CelebA hair-color task, they achieve 90% faithfulness and maintain 96% agreement under Gaussian noise without sacrificing accuracy. Scaling to a Vision Transformer pretrained on ImageNet, we extend cluster paths to concept paths derived from prompting a large language model on minimal path divergences. Finally, we show that cluster paths can serve as an effective out-of-distribution (OOD) detector, reliably flagging anomalous samples before the model generates over-confident predictions. Cluster paths uncover visual concepts, such as color palettes, textures, or object contexts, at multiple network depths, demonstrating that cluster paths scale to large vision models while generating concise and human-readable explanations.</description>
   <guid>oai:arXiv.org:2510.06541v1</guid>
   <category>cs.CV</category>
   <category>cs.LG</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Nicholas M. Kroeger, Vincent Bindschaedler</creator>
  </item>
  <item>
   <title>Validation of Various Normalization Methods for Brain Tumor Segmentation: Can Federated Learning Overcome This Heterogeneity?</title>
   <link>https://arxiv.org/abs/2510.07126</link>
   <description>Deep learning (DL) has been increasingly applied in medical imaging, however, it requires large amounts of data, which raises many challenges related to data privacy, storage, and transfer. Federated learning (FL) is a training paradigm that overcomes these issues, though its effectiveness may be reduced when dealing with non-independent and identically distributed (non-IID) data. This study simulates non-IID conditions by applying different MRI intensity normalization techniques to separate data subsets, reflecting a common cause of heterogeneity. These subsets are then used for training and testing models for brain tumor segmentation. The findings provide insights into the influence of the MRI intensity normalization methods on segmentation models, both training and inference. Notably, the FL methods demonstrated resilience to inconsistently normalized data across clients, achieving the 3D Dice score of 92%, which is comparable to a centralized model (trained using all data). These results indicate that FL is a solution to effectively train high-performing models without violating data privacy, a crucial concern in medical applications. The code is available at: https://github.com/SanoScience/fl-varying-normalization.</description>
   <guid>oai:arXiv.org:2510.07126v1</guid>
   <category>cs.CV</category>
   <category>cs.DC</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Jan Fiszer, Dominika Ciupek, Maciej Malawski</creator>
  </item>
  <item>
   <title>Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods</title>
   <link>https://arxiv.org/abs/2510.07143</link>
   <description>Recent endeavors to accelerate inference in Multimodal Large Language Models (MLLMs) have primarily focused on visual token compression. The effectiveness of these methods is typically assessed by measuring the accuracy drop on established benchmarks, comparing model performance before and after compression. However, these benchmarks are originally designed to assess the perception and reasoning capabilities of MLLMs, rather than to evaluate compression techniques. As a result, directly applying them to visual token compression introduces a task mismatch. Strikingly, our investigation reveals that simple image downsampling consistently outperforms many advanced compression methods across multiple widely used benchmarks. Through extensive experiments, we make the following observations: (i) Current benchmarks are noisy for the visual token compression task. (ii) Down-sampling is able to serve as a data filter to evaluate the difficulty of samples in the visual token compression task. Motivated by these findings, we introduce VTC-Bench, an evaluation framework that incorporates a data filtering mechanism to denoise existing benchmarks, thereby enabling fairer and more accurate assessment of visual token compression methods. All data and code are available at https://github.com/Chenfei-Liao/VTC-Bench.</description>
   <guid>oai:arXiv.org:2510.07143v1</guid>
   <category>cs.CV</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Chenfei Liao, Wensong Wang, Zichen Wen, Xu Zheng, Yiyu Wang, Haocong He, Yuanhuiyi Lyu, Lutao Jiang, Xin Zou, Yuqian Fu, Bin Ren, Linfeng Zhang, Xuming Hu</creator>
  </item>
  <item>
   <title>Is My Data in Your AI? Membership Inference Test (MINT) applied to Face Biometrics</title>
   <link>https://arxiv.org/abs/2402.09225</link>
   <description>This article introduces the Membership Inference Test (MINT), a novel approach that aims to empirically assess if given data was used during the training of AI/ML models. Specifically, we propose two MINT architectures designed to learn the distinct activation patterns that emerge when an Audited Model is exposed to data used during its training process. These architectures are based on Multilayer Perceptrons (MLPs) and Convolutional Neural Networks (CNNs). The experimental framework focuses on the challenging task of Face Recognition, considering three state-of-the-art Face Recognition systems. Experiments are carried out using six publicly available databases, comprising over 22 million face images in total. Different experimental scenarios are considered depending on the context of the AI model to test. Our proposed MINT approach achieves promising results, with up to 90\% accuracy, indicating the potential to recognize if an AI model has been trained with specific data. The proposed MINT approach can serve to enforce privacy and fairness in several AI applications, e.g., revealing if sensitive or private data was used for training or tuning Large Language Models (LLMs).</description>
   <guid>oai:arXiv.org:2402.09225v4</guid>
   <category>cs.CV</category>
   <category>cs.AI</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</rights>
   <creator>Daniel DeAlcala, Aythami Morales, Julian Fierrez, Gonzalo Mancera, Ruben Tolosana, Javier Ortega-Garcia</creator>
  </item>
  <item>
   <title>TalkPlay-Tools: Conversational Music Recommendation with LLM Tool Calling</title>
   <link>https://arxiv.org/abs/2510.01698</link>
   <description>While the recent developments in large language models (LLMs) have successfully enabled generative recommenders with natural language interactions, their recommendation behavior is limited, leaving other simpler yet crucial components such as metadata or attribute filtering underutilized in the system. We propose an LLM-based music recommendation system with tool calling to serve as a unified retrieval-reranking pipeline. Our system positions an LLM as an end-to-end recommendation system that interprets user intent, plans tool invocations, and orchestrates specialized components: boolean filters (SQL), sparse retrieval (BM25), dense retrieval (embedding similarity), and generative retrieval (semantic IDs). Through tool planning, the system predicts which types of tools to use, their execution order, and the arguments needed to find music matching user preferences, supporting diverse modalities while seamlessly integrating multiple database filtering methods. We demonstrate that this unified tool-calling framework achieves competitive performance across diverse recommendation scenarios by selectively employing appropriate retrieval methods based on user queries, envisioning a new paradigm for conversational music recommendation systems.</description>
   <guid>oai:arXiv.org:2510.01698v3</guid>
   <category>cs.IR</category>
   <category>cs.MM</category>
   <category>cs.SD</category>
   <category>eess.AS</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</rights>
   <creator>Seungheon Doh, Keunwoo Choi, Juhan Nam</creator>
  </item>
  <item>
   <title>Federated Unlearning in the Wild: Rethinking Fairness and Data Discrepancy</title>
   <link>https://arxiv.org/abs/2510.07022</link>
   <description>Machine unlearning is critical for enforcing data deletion rights like the &quot;right to be forgotten.&quot; As a decentralized paradigm, Federated Learning (FL) also requires unlearning, but realistic implementations face two major challenges. First, fairness in Federated Unlearning (FU) is often overlooked. Exact unlearning methods typically force all clients into costly retraining, even those uninvolved. Approximate approaches, using gradient ascent or distillation, make coarse interventions that can unfairly degrade performance for clients with only retained data. Second, most FU evaluations rely on synthetic data assumptions (IID/non-IID) that ignore real-world heterogeneity. These unrealistic benchmarks obscure the true impact of unlearning and limit the applicability of current methods. We first conduct a comprehensive benchmark of existing FU methods under realistic data heterogeneity and fairness conditions. We then propose a novel, fairness-aware FU approach, Federated Cross-Client-Constrains Unlearning (FedCCCU), to explicitly address both challenges. FedCCCU offers a practical and scalable solution for real-world FU. Experimental results show that existing methods perform poorly in realistic settings, while our approach consistently outperforms them.</description>
   <guid>oai:arXiv.org:2510.07022v1</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>ZiHeng Huang, Di Wu, Jun Bai, Jiale Zhang, Sicong Cao, Ji Zhang, Yingjie Hu</creator>
  </item>
  <item>
   <title>DPMM-CFL: Clustered Federated Learning via Dirichlet Process Mixture Model Nonparametric Clustering</title>
   <link>https://arxiv.org/abs/2510.07132</link>
   <description>Clustered Federated Learning (CFL) improves performance under non-IID client heterogeneity by clustering clients and training one model per cluster, thereby balancing between a global model and fully personalized models. However, most CFL methods require the number of clusters K to be fixed a priori, which is impractical when the latent structure is unknown. We propose DPMM-CFL, a CFL algorithm that places a Dirichlet Process (DP) prior over the distribution of cluster parameters. This enables nonparametric Bayesian inference to jointly infer both the number of clusters and client assignments, while optimizing per-cluster federated objectives. This results in a method where, at each round, federated updates and cluster inferences are coupled, as presented in this paper. The algorithm is validated on benchmark datasets under Dirichlet and class-split non-IID partitions.</description>
   <guid>oai:arXiv.org:2510.07132v1</guid>
   <category>cs.LG</category>
   <category>cs.DC</category>
   <category>stat.ML</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Mariona Jaramillo-Civill, Peng Wu, Pau Closas</creator>
  </item>
  <item>
   <title>Layerwise Federated Learning for Heterogeneous Quantum Clients using Quorus</title>
   <link>https://arxiv.org/abs/2510.06228</link>
   <description>Quantum machine learning (QML) holds the promise to solve classically intractable problems, but, as critical data can be fragmented across private clients, there is a need for distributed QML in a quantum federated learning (QFL) format. However, the quantum computers that different clients have access to can be error-prone and have heterogeneous error properties, requiring them to run circuits of different depths. We propose a novel solution to this QFL problem, Quorus, that utilizes a layerwise loss function for effective training of varying-depth quantum models, which allows clients to choose models for high-fidelity output based on their individual capacity. Quorus also presents various model designs based on client needs that optimize for shot budget, qubit count, midcircuit measurement, and optimization space. Our simulation and real-hardware results show the promise of Quorus: it increases the magnitude of gradients of higher depth clients and improves testing accuracy by 12.4% on average over the state-of-the-art.</description>
   <guid>oai:arXiv.org:2510.06228v1</guid>
   <category>quant-ph</category>
   <category>cs.DC</category>
   <category>cs.ET</category>
   <category>cs.LG</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Jason Han, Nicholas S. DiBrita, Daniel Leeds, Jianqiang Li, Jason Ludmir, Tirthak Patel</creator>
  </item>
  <item>
   <title>Beyond Static Knowledge Messengers: Towards Adaptive, Fair, and Scalable Federated Learning for Medical AI</title>
   <link>https://arxiv.org/abs/2510.06259</link>
   <description>Medical AI faces challenges in privacy-preserving collaborative learning while ensuring fairness across heterogeneous healthcare institutions. Current federated learning approaches suffer from static architectures, slow convergence (45-73 rounds), fairness gaps marginalizing smaller institutions, and scalability constraints (15-client limit). We propose Adaptive Fair Federated Learning (AFFL) through three innovations: (1) Adaptive Knowledge Messengers dynamically scaling capacity based on heterogeneity and task complexity, (2) Fairness-Aware Distillation using influence-weighted aggregation, and (3) Curriculum-Guided Acceleration reducing rounds by 60-70%. Our theoretical analysis provides convergence guarantees with epsilon-fairness bounds, achieving O(T^{-1/2}) + O(H_max/T^{3/4}) rates. Projected results show 55-75% communication reduction, 56-68% fairness improvement, 34-46% energy savings, and 100+ institution support. The framework enables multi-modal integration across imaging, genomics, EHR, and sensor data while maintaining HIPAA/GDPR compliance. We propose MedFedBench benchmark suite for standardized evaluation across six healthcare dimensions: convergence efficiency, institutional fairness, privacy preservation, multi-modal integration, scalability, and clinical deployment readiness. Economic projections indicate 400-800% ROI for rural hospitals and 15-25% performance gains for academic centers. This work presents a seven-question research agenda, 24-month implementation roadmap, and pathways toward democratizing healthcare AI.</description>
   <guid>oai:arXiv.org:2510.06259v1</guid>
   <category>cs.CY</category>
   <category>cs.LG</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</rights>
   <creator>Jahidul Arafat, Fariha Tasmin, Sanjaya Poudel, Ahsan Habib Tareq, Iftekhar Haider</creator>
  </item>
  <item>
   <title>Cluster Paths: Navigating Interpretability in Neural Networks</title>
   <link>https://arxiv.org/abs/2510.06541</link>
   <description>While modern deep neural networks achieve impressive performance in vision tasks, they remain opaque in their decision processes, risking unwarranted trust, undetected biases and unexpected failures. We propose cluster paths, a post-hoc interpretability method that clusters activations at selected layers and represents each input as its sequence of cluster IDs. To assess these cluster paths, we introduce four metrics: path complexity (cognitive load), weighted-path purity (class alignment), decision-alignment faithfulness (predictive fidelity), and path agreement (stability under perturbations). In a spurious-cue CIFAR-10 experiment, cluster paths identify color-based shortcuts and collapse when the cue is removed. On a five-class CelebA hair-color task, they achieve 90% faithfulness and maintain 96% agreement under Gaussian noise without sacrificing accuracy. Scaling to a Vision Transformer pretrained on ImageNet, we extend cluster paths to concept paths derived from prompting a large language model on minimal path divergences. Finally, we show that cluster paths can serve as an effective out-of-distribution (OOD) detector, reliably flagging anomalous samples before the model generates over-confident predictions. Cluster paths uncover visual concepts, such as color palettes, textures, or object contexts, at multiple network depths, demonstrating that cluster paths scale to large vision models while generating concise and human-readable explanations.</description>
   <guid>oai:arXiv.org:2510.06541v1</guid>
   <category>cs.CV</category>
   <category>cs.LG</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Nicholas M. Kroeger, Vincent Bindschaedler</creator>
  </item>
  <item>
   <title>Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense</title>
   <link>https://arxiv.org/abs/2510.07242</link>
   <description>Post-training for reasoning of large language models (LLMs) increasingly relies on verifiable rewards: deterministic checkers that provide 0-1 correctness signals. While reliable, such binary feedback is brittle--many tasks admit partially correct or alternative answers that verifiers under-credit, and the resulting all-or-nothing supervision limits learning. Reward models offer richer, continuous feedback, which can serve as a complementary supervisory signal to verifiers. We introduce HERO (Hybrid Ensemble Reward Optimization), a reinforcement learning framework that integrates verifier signals with reward-model scores in a structured way. HERO employs stratified normalization to bound reward-model scores within verifier-defined groups, preserving correctness while refining quality distinctions, and variance-aware weighting to emphasize challenging prompts where dense signals matter most. Across diverse mathematical reasoning benchmarks, HERO consistently outperforms RM-only and verifier-only baselines, with strong gains on both verifiable and hard-to-verify tasks. Our results show that hybrid reward design retains the stability of verifiers while leveraging the nuance of reward models to advance reasoning.</description>
   <guid>oai:arXiv.org:2510.07242v1</guid>
   <category>cs.CL</category>
   <category>cs.LG</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Leitian Tao, Ilia Kulikov, Swarnadeep Saha, Tianlu Wang, Jing Xu, Yixuan Li, Jason E Weston, Ping Yu</creator>
  </item>
  <item>
   <title>Differential Privacy for Adaptive Weight Aggregation in Federated Tumor Segmentation</title>
   <link>https://arxiv.org/abs/2308.00856</link>
   <description>Federated Learning (FL) is a distributed machine learning approach that safeguards privacy by creating an impartial global model while respecting the privacy of individual client data. However, the conventional FL method can introduce security risks when dealing with diverse client data, potentially compromising privacy and data integrity. To address these challenges, we present a differential privacy (DP) federated deep learning framework in medical image segmentation. In this paper, we extend our similarity weight aggregation (SimAgg) method to DP-SimAgg algorithm, a differentially private similarity-weighted aggregation algorithm for brain tumor segmentation in multi-modal magnetic resonance imaging (MRI). Our DP-SimAgg method not only enhances model segmentation capabilities but also provides an additional layer of privacy preservation. Extensive benchmarking and evaluation of our framework, with computational performance as a key consideration, demonstrate that DP-SimAgg enables accurate and robust brain tumor segmentation while minimizing communication costs during model training. This advancement is crucial for preserving the privacy of medical image data and safeguarding sensitive information. In conclusion, adding a differential privacy layer in the global weight aggregation phase of the federated brain tumor segmentation provides a promising solution to privacy concerns without compromising segmentation model efficacy. By leveraging DP, we ensure the protection of client data against adversarial attacks and malicious participants.</description>
   <guid>oai:arXiv.org:2308.00856v2</guid>
   <category>cs.LG</category>
   <category>cs.CR</category>
   <category>eess.IV</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Muhammad Irfan Khan, Esa Alhoniemi, Elina Kontio, Suleiman A. Khan, Mojtaba Jafaritadi</creator>
  </item>
  <item>
   <title>FedAGHN: Personalized Federated Learning with Attentive Graph HyperNetworks</title>
   <link>https://arxiv.org/abs/2501.16379</link>
   <description>Personalized Federated Learning (PFL) aims to address the statistical heterogeneity of data across clients by learning the personalized model for each client. Among various PFL approaches, the personalized aggregation-based approach conducts parameter aggregation in the server-side aggregation phase to generate personalized models, and focuses on learning appropriate collaborative relationships among clients for aggregation. However, the collaborative relationships vary in different scenarios and even at different stages of the FL process. To this end, we propose Personalized Federated Learning with Attentive Graph HyperNetworks (FedAGHN), which employs Attentive Graph HyperNetworks (AGHNs) to dynamically capture fine-grained collaborative relationships and generate client-specific personalized initial models. Specifically, AGHNs empower graphs to explicitly model the client-specific collaborative relationships, construct collaboration graphs, and introduce tunable attentive mechanism to derive the collaboration weights, so that the personalized initial models can be obtained by aggregating parameters over the collaboration graphs. Extensive experiments can demonstrate the superiority of FedAGHN. Moreover, a series of visualizations are presented to explore the effectiveness of collaboration graphs learned by FedAGHN.</description>
   <guid>oai:arXiv.org:2501.16379v2</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</rights>
   <creator>Jiarui Song, Yunheng Shen, Chengbin Hou, Pengyu Wang, Jinbao Wang, Ke Tang, Hairong Lv</creator>
  </item>
  <item>
   <title>A Novel Collaborative Framework for Efficient Synchronization in Split Federated Learning over Wireless Networks</title>
   <link>https://arxiv.org/abs/2503.15559</link>
   <description>Split Federated Learning (SFL) offers a promising approach for distributed model training in wireless networks, combining the layer-partitioning advantages of split learning with the federated aggregation that ensures global convergence. However, in heterogeneous wireless environments, disparities in device capabilities and channel conditions make strict round-based synchronization heavily straggler-dominated, thereby limiting both efficiency and scalability. To address this challenge, we propose a new framework, called Collaborative Split Federated Learning (CSFL), that redefines workload redistribution through device-to-device collaboration. Building on the flexibility of model partitioning, CSFL enables efficient devices, after completing their own forward propagation, to seamlessly take over the unfinished layers of bottleneck devices. This collaborative process, supported by D2D communications, allows bottleneck devices to offload computation earlier while maintaining synchronized progression across the network. Beyond the system design, we highlight key technical enablers such as privacy protection, multi-perspective matching, and incentive mechanisms, and discuss practical challenges including matching balance, privacy risks, and incentive sustainability. A case study demonstrates that CSFL significantly reduces training latency without compromising convergence speed or accuracy, underscoring collaboration as a key enabler for synchronization-efficient learning in next-generation wireless networks.</description>
   <guid>oai:arXiv.org:2503.15559v2</guid>
   <category>cs.LG</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Haoran Gao, Samuel D. Okegbile, Jun Cai</creator>
  </item>
  <item>
   <title>ProCut: LLM Prompt Compression via Attribution Estimation</title>
   <link>https://arxiv.org/abs/2508.02053</link>
   <description>In large-scale industrial LLM systems, prompt templates often expand to thousands of tokens as teams iteratively incorporate sections such as task instructions, few-shot examples, and heuristic rules to enhance robustness and coverage. This expansion leads to bloated prompts that are difficult to maintain and incur significant inference latency and serving costs. To address this, we introduce Prompt Compression via Attribution Estimation (ProCut), a flexible, LLM-agnostic, training-free framework that compresses prompts through attribution analysis. ProCut segments prompt templates into semantically meaningful units, quantifies their impact on task performance, and prunes low-utility components. Through extensive experiments on five public benchmark datasets and real-world industrial prompts, we show that ProCut achieves substantial prompt size reductions (78% fewer tokens in production) while maintaining or even slightly improving task performance (up to 62% better than alternative methods). We further introduce an LLM-driven attribution estimator that reduces compression latency by over 50%, and demonstrate that ProCut integrates seamlessly with existing prompt-optimization frameworks to produce concise, high-performing prompts.</description>
   <guid>oai:arXiv.org:2508.02053v2</guid>
   <category>cs.CL</category>
   <category>cs.LG</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</rights>
   <creator>Zhentao Xu, Fengyi Li, Albert Chen, Xiaofeng Wang</creator>
  </item>
  <item>
   <title>TalkPlay-Tools: Conversational Music Recommendation with LLM Tool Calling</title>
   <link>https://arxiv.org/abs/2510.01698</link>
   <description>While the recent developments in large language models (LLMs) have successfully enabled generative recommenders with natural language interactions, their recommendation behavior is limited, leaving other simpler yet crucial components such as metadata or attribute filtering underutilized in the system. We propose an LLM-based music recommendation system with tool calling to serve as a unified retrieval-reranking pipeline. Our system positions an LLM as an end-to-end recommendation system that interprets user intent, plans tool invocations, and orchestrates specialized components: boolean filters (SQL), sparse retrieval (BM25), dense retrieval (embedding similarity), and generative retrieval (semantic IDs). Through tool planning, the system predicts which types of tools to use, their execution order, and the arguments needed to find music matching user preferences, supporting diverse modalities while seamlessly integrating multiple database filtering methods. We demonstrate that this unified tool-calling framework achieves competitive performance across diverse recommendation scenarios by selectively employing appropriate retrieval methods based on user queries, envisioning a new paradigm for conversational music recommendation systems.</description>
   <guid>oai:arXiv.org:2510.01698v3</guid>
   <category>cs.IR</category>
   <category>cs.MM</category>
   <category>cs.SD</category>
   <category>eess.AS</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</rights>
   <creator>Seungheon Doh, Keunwoo Choi, Juhan Nam</creator>
  </item>
  <item>
   <title>CoT Referring: Improving Referring Expression Tasks with Grounded Reasoning</title>
   <link>https://arxiv.org/abs/2510.06243</link>
   <description>Referring Expression Comprehension and Segmentation are critical tasks for assessing the integration of language understanding and image comprehension, serving as benchmarks for Multimodal Large Language Models (MLLMs) capabilities. To address these challenges, we propose a new strategy, CoT Referring, which enhances model reasoning across modalities through a structured, chain-of-thought training data structure. Our approach systematically parses textual structures to a sequential referring step, where in each step it identifies relationships and ensures consistent reference alignment, thereby improving accuracy in complex query scenarios. We restructure the training data to enforce a new output form, providing new annotations for existing datasets and compiling an evaluation benchmark from existing resources. This benchmark is designed explicitly for complex referring cases. We also integrate detection and segmentation capabilities into a unified MLLM framework, training it with a novel adaptive weighted loss to optimize performance. Experimental results on our curated benchmark and RefCOCO/+/g demonstrate the effectiveness of our approach, with a notable increase of 2.5%+ over baseline models.</description>
   <guid>oai:arXiv.org:2510.06243v1</guid>
   <category>cs.CL</category>
   <category>cs.AI</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Qihua Dong, Luis Figueroa, Handong Zhao, Kushal Kafle, Jason Kuen, Zhihong Ding, Scott Cohen, Yun Fu</creator>
  </item>
  <item>
   <title>Federated Unlearning in the Wild: Rethinking Fairness and Data Discrepancy</title>
   <link>https://arxiv.org/abs/2510.07022</link>
   <description>Machine unlearning is critical for enforcing data deletion rights like the &quot;right to be forgotten.&quot; As a decentralized paradigm, Federated Learning (FL) also requires unlearning, but realistic implementations face two major challenges. First, fairness in Federated Unlearning (FU) is often overlooked. Exact unlearning methods typically force all clients into costly retraining, even those uninvolved. Approximate approaches, using gradient ascent or distillation, make coarse interventions that can unfairly degrade performance for clients with only retained data. Second, most FU evaluations rely on synthetic data assumptions (IID/non-IID) that ignore real-world heterogeneity. These unrealistic benchmarks obscure the true impact of unlearning and limit the applicability of current methods. We first conduct a comprehensive benchmark of existing FU methods under realistic data heterogeneity and fairness conditions. We then propose a novel, fairness-aware FU approach, Federated Cross-Client-Constrains Unlearning (FedCCCU), to explicitly address both challenges. FedCCCU offers a practical and scalable solution for real-world FU. Experimental results show that existing methods perform poorly in realistic settings, while our approach consistently outperforms them.</description>
   <guid>oai:arXiv.org:2510.07022v1</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>ZiHeng Huang, Di Wu, Jun Bai, Jiale Zhang, Sicong Cao, Ji Zhang, Yingjie Hu</creator>
  </item>
  <item>
   <title>Is My Data in Your AI? Membership Inference Test (MINT) applied to Face Biometrics</title>
   <link>https://arxiv.org/abs/2402.09225</link>
   <description>This article introduces the Membership Inference Test (MINT), a novel approach that aims to empirically assess if given data was used during the training of AI/ML models. Specifically, we propose two MINT architectures designed to learn the distinct activation patterns that emerge when an Audited Model is exposed to data used during its training process. These architectures are based on Multilayer Perceptrons (MLPs) and Convolutional Neural Networks (CNNs). The experimental framework focuses on the challenging task of Face Recognition, considering three state-of-the-art Face Recognition systems. Experiments are carried out using six publicly available databases, comprising over 22 million face images in total. Different experimental scenarios are considered depending on the context of the AI model to test. Our proposed MINT approach achieves promising results, with up to 90\% accuracy, indicating the potential to recognize if an AI model has been trained with specific data. The proposed MINT approach can serve to enforce privacy and fairness in several AI applications, e.g., revealing if sensitive or private data was used for training or tuning Large Language Models (LLMs).</description>
   <guid>oai:arXiv.org:2402.09225v4</guid>
   <category>cs.CV</category>
   <category>cs.AI</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</rights>
   <creator>Daniel DeAlcala, Aythami Morales, Julian Fierrez, Gonzalo Mancera, Ruben Tolosana, Javier Ortega-Garcia</creator>
  </item>
  <item>
   <title>KunServe: Parameter-centric Memory Management for Efficient Memory Overloading Handling in LLM Serving</title>
   <link>https://arxiv.org/abs/2412.18169</link>
   <description>Serving LLMs with a cluster of GPUs is common nowadays, where the serving system must meet strict latency SLOs required by applications. However, the stateful nature of LLM serving requires maintaining huge states (i.e., KVCache) in limited GPU memory. Under spikes in real-world workloads, GPU memory can be easily throttled, leading to orders of magnitude higher response latency due to queuing introduced by waiting for KVCache to be reclaimed. Prior KVCache-centric approaches handle load throttling by dropping, migrating, or swapping KVCache. These methods fail to release sufficient memory quickly with requests still queued.
  This paper proposes the first parameter-centric approach to handling throttling by selectively dropping replicated parameters to instantly free memory for requests, based on an unnoticed observation that model parameters are commonly replicated across GPUs for serving LLMs. With additional memory, all requests can be served with a larger batch without queuing. To make the parameter-centric approach correct and efficient, we cooperatively execute requests on GPUs with a complete copy of parameters using pipeline parallelism, and derive an appropriate drop plan without unnecessary cooperation. We also design techniques to minimize the performance overhead due to pipeline parallelism with the execution patterns of requests under drop. Evaluations show that {\sys} reduces the tail TTFT of requests under throttling by up to 72.2 times compared to the state-of-the-art systems including Llumnix, vLLM and InferCept.</description>
   <guid>oai:arXiv.org:2412.18169v5</guid>
   <category>cs.DC</category>
   <category>cs.AI</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Rongxin Cheng, Yuxin Lai, Xingda Wei, Rong Chen, Haibo Chen</creator>
  </item>
  <item>
   <title>FedAGHN: Personalized Federated Learning with Attentive Graph HyperNetworks</title>
   <link>https://arxiv.org/abs/2501.16379</link>
   <description>Personalized Federated Learning (PFL) aims to address the statistical heterogeneity of data across clients by learning the personalized model for each client. Among various PFL approaches, the personalized aggregation-based approach conducts parameter aggregation in the server-side aggregation phase to generate personalized models, and focuses on learning appropriate collaborative relationships among clients for aggregation. However, the collaborative relationships vary in different scenarios and even at different stages of the FL process. To this end, we propose Personalized Federated Learning with Attentive Graph HyperNetworks (FedAGHN), which employs Attentive Graph HyperNetworks (AGHNs) to dynamically capture fine-grained collaborative relationships and generate client-specific personalized initial models. Specifically, AGHNs empower graphs to explicitly model the client-specific collaborative relationships, construct collaboration graphs, and introduce tunable attentive mechanism to derive the collaboration weights, so that the personalized initial models can be obtained by aggregating parameters over the collaboration graphs. Extensive experiments can demonstrate the superiority of FedAGHN. Moreover, a series of visualizations are presented to explore the effectiveness of collaboration graphs learned by FedAGHN.</description>
   <guid>oai:arXiv.org:2501.16379v2</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</rights>
   <creator>Jiarui Song, Yunheng Shen, Chengbin Hou, Pengyu Wang, Jinbao Wang, Ke Tang, Hairong Lv</creator>
  </item>
  <item>
   <title>Layerwise Federated Learning for Heterogeneous Quantum Clients using Quorus</title>
   <link>https://arxiv.org/abs/2510.06228</link>
   <description>Quantum machine learning (QML) holds the promise to solve classically intractable problems, but, as critical data can be fragmented across private clients, there is a need for distributed QML in a quantum federated learning (QFL) format. However, the quantum computers that different clients have access to can be error-prone and have heterogeneous error properties, requiring them to run circuits of different depths. We propose a novel solution to this QFL problem, Quorus, that utilizes a layerwise loss function for effective training of varying-depth quantum models, which allows clients to choose models for high-fidelity output based on their individual capacity. Quorus also presents various model designs based on client needs that optimize for shot budget, qubit count, midcircuit measurement, and optimization space. Our simulation and real-hardware results show the promise of Quorus: it increases the magnitude of gradients of higher depth clients and improves testing accuracy by 12.4% on average over the state-of-the-art.</description>
   <guid>oai:arXiv.org:2510.06228v1</guid>
   <category>quant-ph</category>
   <category>cs.DC</category>
   <category>cs.ET</category>
   <category>cs.LG</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Jason Han, Nicholas S. DiBrita, Daniel Leeds, Jianqiang Li, Jason Ludmir, Tirthak Patel</creator>
  </item>
  <item>
   <title>Validation of Various Normalization Methods for Brain Tumor Segmentation: Can Federated Learning Overcome This Heterogeneity?</title>
   <link>https://arxiv.org/abs/2510.07126</link>
   <description>Deep learning (DL) has been increasingly applied in medical imaging, however, it requires large amounts of data, which raises many challenges related to data privacy, storage, and transfer. Federated learning (FL) is a training paradigm that overcomes these issues, though its effectiveness may be reduced when dealing with non-independent and identically distributed (non-IID) data. This study simulates non-IID conditions by applying different MRI intensity normalization techniques to separate data subsets, reflecting a common cause of heterogeneity. These subsets are then used for training and testing models for brain tumor segmentation. The findings provide insights into the influence of the MRI intensity normalization methods on segmentation models, both training and inference. Notably, the FL methods demonstrated resilience to inconsistently normalized data across clients, achieving the 3D Dice score of 92%, which is comparable to a centralized model (trained using all data). These results indicate that FL is a solution to effectively train high-performing models without violating data privacy, a crucial concern in medical applications. The code is available at: https://github.com/SanoScience/fl-varying-normalization.</description>
   <guid>oai:arXiv.org:2510.07126v1</guid>
   <category>cs.CV</category>
   <category>cs.DC</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Jan Fiszer, Dominika Ciupek, Maciej Malawski</creator>
  </item>
  <item>
   <title>DPMM-CFL: Clustered Federated Learning via Dirichlet Process Mixture Model Nonparametric Clustering</title>
   <link>https://arxiv.org/abs/2510.07132</link>
   <description>Clustered Federated Learning (CFL) improves performance under non-IID client heterogeneity by clustering clients and training one model per cluster, thereby balancing between a global model and fully personalized models. However, most CFL methods require the number of clusters K to be fixed a priori, which is impractical when the latent structure is unknown. We propose DPMM-CFL, a CFL algorithm that places a Dirichlet Process (DP) prior over the distribution of cluster parameters. This enables nonparametric Bayesian inference to jointly infer both the number of clusters and client assignments, while optimizing per-cluster federated objectives. This results in a method where, at each round, federated updates and cluster inferences are coupled, as presented in this paper. The algorithm is validated on benchmark datasets under Dirichlet and class-split non-IID partitions.</description>
   <guid>oai:arXiv.org:2510.07132v1</guid>
   <category>cs.LG</category>
   <category>cs.DC</category>
   <category>stat.ML</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Mariona Jaramillo-Civill, Peng Wu, Pau Closas</creator>
  </item>
  <item>
   <title>KunServe: Parameter-centric Memory Management for Efficient Memory Overloading Handling in LLM Serving</title>
   <link>https://arxiv.org/abs/2412.18169</link>
   <description>Serving LLMs with a cluster of GPUs is common nowadays, where the serving system must meet strict latency SLOs required by applications. However, the stateful nature of LLM serving requires maintaining huge states (i.e., KVCache) in limited GPU memory. Under spikes in real-world workloads, GPU memory can be easily throttled, leading to orders of magnitude higher response latency due to queuing introduced by waiting for KVCache to be reclaimed. Prior KVCache-centric approaches handle load throttling by dropping, migrating, or swapping KVCache. These methods fail to release sufficient memory quickly with requests still queued.
  This paper proposes the first parameter-centric approach to handling throttling by selectively dropping replicated parameters to instantly free memory for requests, based on an unnoticed observation that model parameters are commonly replicated across GPUs for serving LLMs. With additional memory, all requests can be served with a larger batch without queuing. To make the parameter-centric approach correct and efficient, we cooperatively execute requests on GPUs with a complete copy of parameters using pipeline parallelism, and derive an appropriate drop plan without unnecessary cooperation. We also design techniques to minimize the performance overhead due to pipeline parallelism with the execution patterns of requests under drop. Evaluations show that {\sys} reduces the tail TTFT of requests under throttling by up to 72.2 times compared to the state-of-the-art systems including Llumnix, vLLM and InferCept.</description>
   <guid>oai:arXiv.org:2412.18169v5</guid>
   <category>cs.DC</category>
   <category>cs.AI</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Rongxin Cheng, Yuxin Lai, Xingda Wei, Rong Chen, Haibo Chen</creator>
  </item>
  <item>
   <title>LLM-Powered Nuanced Video Attribute Annotation for Enhanced Recommendations</title>
   <link>https://arxiv.org/abs/2510.06657</link>
   <description>This paper presents a case study on deploying Large Language Models (LLMs) as an advanced &quot;annotation&quot; mechanism to achieve nuanced content understanding (e.g., discerning content &quot;vibe&quot;) at scale within a large-scale industrial short-form video recommendation system. Traditional machine learning classifiers for content understanding face protracted development cycles and a lack of deep, nuanced comprehension. The &quot;LLM-as-annotators&quot; approach addresses these by significantly shortening development times and enabling the annotation of subtle attributes. This work details an end-to-end workflow encompassing: (1) iterative definition and robust evaluation of target attributes, refined by offline metrics and online A/B testing; (2) scalable offline bulk annotation of video corpora using LLMs with multimodal features, optimized inference, and knowledge distillation for broad application; and (3) integration of these rich annotations into the online recommendation serving system, for example, through personalized restrict retrieval. Experimental results demonstrate the efficacy of this approach, with LLMs outperforming human raters in offline annotation quality for nuanced attributes and yielding significant improvements of user participation and satisfied consumption in online A/B tests. The study provides insights into designing and scaling production-level LLM pipelines for rich content evaluation, highlighting the adaptability and benefits of LLM-generated nuanced understanding for enhancing content discovery, user satisfaction, and the overall effectiveness of modern recommendation systems.</description>
   <guid>oai:arXiv.org:2510.06657v1</guid>
   <category>cs.IR</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</rights>
   <creator>Boyuan Long, Yueqi Wang, Hiloni Mehta, Mick Zomnir, Omkar Pathak, Changping Meng, Ruolin Jia, Yajun Peng, Dapeng Hong, Xia Wu, Mingyan Gao, Onkar Dalal, Ningren Han</creator>
  </item>
  <item>
   <title>TalkPlay-Tools: Conversational Music Recommendation with LLM Tool Calling</title>
   <link>https://arxiv.org/abs/2510.01698</link>
   <description>While the recent developments in large language models (LLMs) have successfully enabled generative recommenders with natural language interactions, their recommendation behavior is limited, leaving other simpler yet crucial components such as metadata or attribute filtering underutilized in the system. We propose an LLM-based music recommendation system with tool calling to serve as a unified retrieval-reranking pipeline. Our system positions an LLM as an end-to-end recommendation system that interprets user intent, plans tool invocations, and orchestrates specialized components: boolean filters (SQL), sparse retrieval (BM25), dense retrieval (embedding similarity), and generative retrieval (semantic IDs). Through tool planning, the system predicts which types of tools to use, their execution order, and the arguments needed to find music matching user preferences, supporting diverse modalities while seamlessly integrating multiple database filtering methods. We demonstrate that this unified tool-calling framework achieves competitive performance across diverse recommendation scenarios by selectively employing appropriate retrieval methods based on user queries, envisioning a new paradigm for conversational music recommendation systems.</description>
   <guid>oai:arXiv.org:2510.01698v3</guid>
   <category>cs.IR</category>
   <category>cs.MM</category>
   <category>cs.SD</category>
   <category>eess.AS</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</rights>
   <creator>Seungheon Doh, Keunwoo Choi, Juhan Nam</creator>
  </item>
  <item>
   <title>CoT Referring: Improving Referring Expression Tasks with Grounded Reasoning</title>
   <link>https://arxiv.org/abs/2510.06243</link>
   <description>Referring Expression Comprehension and Segmentation are critical tasks for assessing the integration of language understanding and image comprehension, serving as benchmarks for Multimodal Large Language Models (MLLMs) capabilities. To address these challenges, we propose a new strategy, CoT Referring, which enhances model reasoning across modalities through a structured, chain-of-thought training data structure. Our approach systematically parses textual structures to a sequential referring step, where in each step it identifies relationships and ensures consistent reference alignment, thereby improving accuracy in complex query scenarios. We restructure the training data to enforce a new output form, providing new annotations for existing datasets and compiling an evaluation benchmark from existing resources. This benchmark is designed explicitly for complex referring cases. We also integrate detection and segmentation capabilities into a unified MLLM framework, training it with a novel adaptive weighted loss to optimize performance. Experimental results on our curated benchmark and RefCOCO/+/g demonstrate the effectiveness of our approach, with a notable increase of 2.5%+ over baseline models.</description>
   <guid>oai:arXiv.org:2510.06243v1</guid>
   <category>cs.CL</category>
   <category>cs.AI</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Qihua Dong, Luis Figueroa, Handong Zhao, Kushal Kafle, Jason Kuen, Zhihong Ding, Scott Cohen, Yun Fu</creator>
  </item>
  <item>
   <title>CARPAS: Towards Content-Aware Refinement of Provided Aspects for Summarization in Large Language Models</title>
   <link>https://arxiv.org/abs/2510.07177</link>
   <description>Aspect-based summarization has attracted significant attention for its ability to generate more fine-grained and user-aligned summaries. While most existing approaches assume a set of predefined aspects as input, real-world scenarios often present challenges where these given aspects may be incomplete, irrelevant, or entirely missing from the document. Users frequently expect systems to adaptively refine or filter the provided aspects based on the actual content. In this paper, we initiate this novel task setting, termed Content-Aware Refinement of Provided Aspects for Summarization (CARPAS), with the aim of dynamically adjusting the provided aspects based on the document context before summarizing. We construct three new datasets to facilitate our pilot experiments, and by using LLMs with four representative prompting strategies in this task, we find that LLMs tend to predict an overly comprehensive set of aspects, which often results in excessively long and misaligned summaries. Building on this observation, we propose a preliminary subtask to predict the number of relevant aspects, and demonstrate that the predicted number can serve as effective guidance for the LLMs, reducing the inference difficulty, and enabling them to focus on the most pertinent aspects. Our extensive experiments show that the proposed approach significantly improves performance across all datasets. Moreover, our deeper analyses uncover LLMs' compliance when the requested number of aspects differs from their own estimations, establishing a crucial insight for the deployment of LLMs in similar real-world applications.</description>
   <guid>oai:arXiv.org:2510.07177v1</guid>
   <category>cs.CL</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Yong-En Tian, Yu-Chien Tang, An-Zi Yen, Wen-Chih Peng</creator>
  </item>
  <item>
   <title>Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense</title>
   <link>https://arxiv.org/abs/2510.07242</link>
   <description>Post-training for reasoning of large language models (LLMs) increasingly relies on verifiable rewards: deterministic checkers that provide 0-1 correctness signals. While reliable, such binary feedback is brittle--many tasks admit partially correct or alternative answers that verifiers under-credit, and the resulting all-or-nothing supervision limits learning. Reward models offer richer, continuous feedback, which can serve as a complementary supervisory signal to verifiers. We introduce HERO (Hybrid Ensemble Reward Optimization), a reinforcement learning framework that integrates verifier signals with reward-model scores in a structured way. HERO employs stratified normalization to bound reward-model scores within verifier-defined groups, preserving correctness while refining quality distinctions, and variance-aware weighting to emphasize challenging prompts where dense signals matter most. Across diverse mathematical reasoning benchmarks, HERO consistently outperforms RM-only and verifier-only baselines, with strong gains on both verifiable and hard-to-verify tasks. Our results show that hybrid reward design retains the stability of verifiers while leveraging the nuance of reward models to advance reasoning.</description>
   <guid>oai:arXiv.org:2510.07242v1</guid>
   <category>cs.CL</category>
   <category>cs.LG</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Leitian Tao, Ilia Kulikov, Swarnadeep Saha, Tianlu Wang, Jing Xu, Yixuan Li, Jason E Weston, Ping Yu</creator>
  </item>
  <item>
   <title>ProCut: LLM Prompt Compression via Attribution Estimation</title>
   <link>https://arxiv.org/abs/2508.02053</link>
   <description>In large-scale industrial LLM systems, prompt templates often expand to thousands of tokens as teams iteratively incorporate sections such as task instructions, few-shot examples, and heuristic rules to enhance robustness and coverage. This expansion leads to bloated prompts that are difficult to maintain and incur significant inference latency and serving costs. To address this, we introduce Prompt Compression via Attribution Estimation (ProCut), a flexible, LLM-agnostic, training-free framework that compresses prompts through attribution analysis. ProCut segments prompt templates into semantically meaningful units, quantifies their impact on task performance, and prunes low-utility components. Through extensive experiments on five public benchmark datasets and real-world industrial prompts, we show that ProCut achieves substantial prompt size reductions (78% fewer tokens in production) while maintaining or even slightly improving task performance (up to 62% better than alternative methods). We further introduce an LLM-driven attribution estimator that reduces compression latency by over 50%, and demonstrate that ProCut integrates seamlessly with existing prompt-optimization frameworks to produce concise, high-performing prompts.</description>
   <guid>oai:arXiv.org:2508.02053v2</guid>
   <category>cs.CL</category>
   <category>cs.LG</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</rights>
   <creator>Zhentao Xu, Fengyi Li, Albert Chen, Xiaofeng Wang</creator>
  </item>
  <item>
   <title>FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient Federated Large Language Models Fine-Tuning</title>
   <link>https://arxiv.org/abs/2510.04601</link>
   <description>The current paradigm of training large language models (LLMs) on publicly available Web data is becoming unsustainable, with high-quality data sources in specialized domains nearing exhaustion. Federated Learning (FL) emerges as a practical solution for the next generation of AI on a decentralized Web, enabling privacy-preserving collaborative fine-tuning by leveraging private data distributed across a global client base. While Low-Rank Adaptation (LoRA) is the standard for efficient fine-tuning, its application in federated settings presents a critical challenge: communication overhead remains a significant bottleneck across the Web's heterogeneous network conditions. The structural redundancy within LoRA parameters not only incurs a heavy communication burden but also introduces conflicts when aggregating client updates. To address this, we propose FedSRD, a Sparsify-Reconstruct-Decompose framework designed for communication-efficient federated LLMs fine-tuning. We first introduce an importance-aware sparsification method that preserves the structural integrity of LoRA updates to reduce the uploaded parameter count. The server then reconstructs and aggregates these updates in a full-rank space to mitigate conflicts. Finally, it decomposes the global update into a sparse low-rank format for broadcast, ensuring a symmetrically efficient cycle. We also propose an efficient variant, FedSRD-e, to reduce computational overhead. Experimental results on 10 benchmarks demonstrate that our framework significantly reduces communication costs by up to 90\% while even improving model performance on heterogeneous client data.</description>
   <guid>oai:arXiv.org:2510.04601v2</guid>
   <category>cs.CL</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Guochen Yan, Luyuan Xie, Qingni Shen, Yuejian Fang, Zhonghai Wu</creator>
  </item>
  <item>
   <title>AI for Abolition? A Participatory Design Approach</title>
   <link>https://arxiv.org/abs/2510.07156</link>
   <description>The abolitionist community faces challenges from both the carceral state and oppressive technologies which, by empowering the ruling class who have the resources to develop artificial intelligence (AI), serve to entrench societal inequities even more deeply. This paper presents a case study in participatory design with transformative and restorative justice practitioners with the goal of designing an AI system to support their work. By co-designing an evaluation framework for large language models with the practitioners, we hope to push back against the exclusionary status quo of AI and extent AI's potentiality to a historically marginalized community.</description>
   <guid>oai:arXiv.org:2510.07156v1</guid>
   <category>cs.HC</category>
   <pubdate>Thu, 09 Oct 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Carolyn Wang, Avriel Epps, Taylor Ferrari, Ra Ames</creator>
  </item>
 </channel>
</rss>
