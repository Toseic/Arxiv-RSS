<?xml version="1.0" ?>
<rss>
 <channel>
  <title>arxiv-rss</title>
  <link></link>
  <description></description>
  <docs></docs>
  <language>en-us</language>
  <lastBuildDate>Wed, 05 Mar 2025 02:49:48 </lastBuildDate>
  <managingEditor></managingEditor>
  <pubDate>Wed, 05 Mar 2025 02:49:48 </pubDate>
  <item>
   <title>User Intent to Use DeepSeek for Healthcare Purposes and their Trust in the Large Language Model: Multinational Survey Study</title>
   <link>https://arxiv.org/abs/2502.17487</link>
   <description>Large language models (LLMs) increasingly serve as interactive healthcare resources, yet user acceptance remains underexplored. This study examines how ease of use, perceived usefulness, trust, and risk perception interact to shape intentions to adopt DeepSeek, an emerging LLM-based platform, for healthcare purposes. A cross-sectional survey of 556 participants from India, the United Kingdom, and the United States was conducted to measure perceptions and usage patterns. Structural equation modeling assessed both direct and indirect effects, including potential quadratic relationships. Results revealed that trust plays a pivotal mediating role: ease of use exerts a significant indirect effect on usage intentions through trust, while perceived usefulness contributes to both trust development and direct adoption. By contrast, risk perception negatively affects usage intent, emphasizing the importance of robust data governance and transparency. Notably, significant non-linear paths were observed for ease of use and risk, indicating threshold or plateau effects. The measurement model demonstrated strong reliability and validity, supported by high composite reliabilities, average variance extracted, and discriminant validity measures. These findings extend technology acceptance and health informatics research by illuminating the multifaceted nature of user adoption in sensitive domains. Stakeholders should invest in trust-building strategies, user-centric design, and risk mitigation measures to encourage sustained and safe uptake of LLMs in healthcare. Future work can employ longitudinal designs or examine culture-specific variables to further clarify how user perceptions evolve over time and across different regulatory environments. Such insights are critical for harnessing AI to enhance outcomes.</description>
   <guid>oai:arXiv.org:2502.17487v2</guid>
   <category>cs.AI</category>
   <category>cs.CY</category>
   <category>cs.HC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Avishek Choudhury, Yeganeh Shahsavar, Hamid Shamszare</creator>
  </item>
  <item>
   <title>Heterogeneity Matters even More in Distributed Learning: Study from Generalization Perspective</title>
   <link>https://arxiv.org/abs/2503.01598</link>
   <description>In this paper, we investigate the effect of data heterogeneity across clients on the performance of distributed learning systems, i.e., one-round Federated Learning, as measured by the associated generalization error. Specifically, \(K\) clients have each \(n\) training samples generated independently according to a possibly different data distribution and their individually chosen models are aggregated by a central server. We study the effect of the discrepancy between the clients' data distributions on the generalization error of the aggregated model. First, we establish in-expectation and tail upper bounds on the generalization error in terms of the distributions. In part, the bounds extend the popular Conditional Mutual Information (CMI) bound which was developed for the centralized learning setting, i.e., \(K=1\), to the distributed learning setting with arbitrary number of clients $K \geq 1$. Then, we use a connection with information theoretic rate-distortion theory to derive possibly tighter \textit{lossy} versions of these bounds. Next, we apply our lossy bounds to study the effect of data heterogeneity across clients on the generalization error for distributed classification problem in which each client uses Support Vector Machines (D-SVM). In this case, we establish explicit generalization error bounds which depend explicitly on the data heterogeneity degree. It is shown that the bound gets smaller as the degree of data heterogeneity across clients gets higher, thereby suggesting that D-SVM generalizes better when the dissimilarity between the clients' training samples is bigger. This finding, which goes beyond D-SVM, is validated experimentally through a number of experiments.</description>
   <guid>oai:arXiv.org:2503.01598v1</guid>
   <category>cs.LG</category>
   <category>cs.IT</category>
   <category>math.IT</category>
   <category>stat.ML</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Masoud Kavian, Milad Sefidgaran, Abdellatif Zaidi, Romain Chor</creator>
  </item>
  <item>
   <title>FedBiP: Heterogeneous One-Shot Federated Learning with Personalized Latent Diffusion Models</title>
   <link>https://arxiv.org/abs/2410.04810</link>
   <description>One-Shot Federated Learning (OSFL), a special decentralized machine learning paradigm, has recently gained significant attention. OSFL requires only a single round of client data or model upload, which reduces communication costs and mitigates privacy threats compared to traditional FL. Despite these promising prospects, existing methods face challenges due to client data heterogeneity and limited data quantity when applied to real-world OSFL systems. Recently, Latent Diffusion Models (LDM) have shown remarkable advancements in synthesizing high-quality images through pretraining on large-scale datasets, thereby presenting a potential solution to overcome these issues. However, directly applying pretrained LDM to heterogeneous OSFL results in significant distribution shifts in synthetic data, leading to performance degradation in classification models trained on such data. This issue is particularly pronounced in rare domains, such as medical imaging, which are underrepresented in LDM's pretraining data. To address this challenge, we propose Federated Bi-Level Personalization (FedBiP), which personalizes the pretrained LDM at both instance-level and concept-level. Hereby, FedBiP synthesizes images following the client's local data distribution without compromising the privacy regulations. FedBiP is also the first approach to simultaneously address feature space heterogeneity and client data scarcity in OSFL. Our method is validated through extensive experiments on three OSFL benchmarks with feature space heterogeneity, as well as on challenging medical and satellite image datasets with label heterogeneity. The results demonstrate the effectiveness of FedBiP, which substantially outperforms other OSFL methods.</description>
   <guid>oai:arXiv.org:2410.04810v2</guid>
   <category>cs.LG</category>
   <category>cs.CV</category>
   <category>cs.DC</category>
   <category>cs.MM</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Haokun Chen, Hang Li, Yao Zhang, Jinhe Bi, Gengyuan Zhang, Yueqi Zhang, Philip Torr, Jindong Gu, Denis Krompass, Volker Tresp</creator>
  </item>
  <item>
   <title>Fed-KAN: Federated Learning with Kolmogorov-Arnold Networks for Traffic Prediction</title>
   <link>https://arxiv.org/abs/2503.00154</link>
   <description>Non-Terrestrial Networks (NTNs) are becoming a critical component of modern communication infrastructures, especially with the advent of Low Earth Orbit (LEO) satellite systems. Traditional centralized learning approaches face major challenges in such networks due to high latency, intermittent connectivity and limited bandwidth. Federated Learning (FL) is a promising alternative as it enables decentralized training while maintaining data privacy. However, existing FL models, such as Federated Learning with Multi-Layer Perceptrons (Fed-MLP), can struggle with high computational complexity and poor adaptability to dynamic NTN environments. This paper provides a detailed analysis for Federated Learning with Kolmogorov-Arnold Networks (Fed-KAN), its implementation and performance improvements over traditional FL models in NTN environments for traffic forecasting. The proposed Fed-KAN is a novel approach that utilises the functional approximation capabilities of KANs in a FL framework. We evaluate Fed-KAN compared to Fed-MLP on a traffic dataset of real satellite operator and show a significant reduction in training and test loss. Our results show that Fed-KAN can achieve a 77.39% reduction in average test loss compared to Fed-MLP, highlighting its improved performance and better generalization ability. At the end of the paper, we also discuss some potential applications of Fed-KAN within O-RAN and Fed-KAN usage for split functionalities in NTN architecture.</description>
   <guid>oai:arXiv.org:2503.00154v1</guid>
   <category>cs.NI</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Engin Zeydan, Cristian J. Vaca-Rubio, Luis Blanco, Roberto Pereira, Marius Caus, Kapal Dev</creator>
  </item>
  <item>
   <title>FLStore: Efficient Federated Learning Storage for non-training workloads</title>
   <link>https://arxiv.org/abs/2503.00323</link>
   <description>Federated Learning (FL) is an approach for privacy-preserving Machine Learning (ML), enabling model training across multiple clients without centralized data collection. With an aggregator server coordinating training, aggregating model updates, and storing metadata across rounds. In addition to training, a substantial part of FL systems are the non-training workloads such as scheduling, personalization, clustering, debugging, and incentivization. Most existing systems rely on the aggregator to handle non-training workloads and use cloud services for data storage. This results in high latency and increased costs as non-training workloads rely on large volumes of metadata, including weight parameters from client updates, hyperparameters, and aggregated updates across rounds, making the situation even worse. We propose FLStore, a serverless framework for efficient FL non-training workloads and storage. FLStore unifies the data and compute planes on a serverless cache, enabling locality-aware execution via tailored caching policies to reduce latency and costs. Per our evaluations, compared to cloud object store based aggregator server FLStore reduces per request average latency by 71% and costs by 92.45%, with peak improvements of 99.7% and 98.8%, respectively. Compared to an in-memory cloud cache based aggregator server, FLStore reduces average latency by 64.6% and costs by 98.83%, with peak improvements of 98.8% and 99.6%, respectively. FLStore integrates seamlessly with existing FL frameworks with minimal modifications, while also being fault-tolerant and highly scalable.</description>
   <guid>oai:arXiv.org:2503.00323v1</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Ahmad Faraz Khan, Samuel Fountain, Ahmed M. Abdelmoniem, Ali R. Butt, Ali Anwar</creator>
  </item>
  <item>
   <title>Conditioning on Local Statistics for Scalable Heterogeneous Federated Learning</title>
   <link>https://arxiv.org/abs/2503.00378</link>
   <description>Federated learning is a distributed machine learning approach where multiple clients collaboratively train a model without sharing their local data, which contributes to preserving privacy. A challenge in federated learning is managing heterogeneous data distributions across clients, which can hinder model convergence and performance due to the need for the global model to generalize well across diverse local datasets. We propose to use local characteristic statistics, by which we mean some statistical properties calculated independently by each client using only their local training dataset. These statistics, such as means, covariances, and higher moments, are used to capture the characteristics of the local data distribution. They are not shared with other clients or a central node. During training, these local statistics help the model learn how to condition on the local data distribution, and during inference, they guide the client's predictions. Our experiments show that this approach allows for efficient handling of heterogeneous data across the federation, has favorable scaling compared to approaches that directly try to identify peer nodes that share distribution characteristics, and maintains privacy as no additional information needs to be communicated.</description>
   <guid>oai:arXiv.org:2503.00378v1</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <category>cs.CR</category>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Rickard Br\&quot;annvall</creator>
  </item>
  <item>
   <title>Progressive Sparse Attention: Algorithm and System Co-design for Efficient Attention in LLM Serving</title>
   <link>https://arxiv.org/abs/2503.00392</link>
   <description>Processing long contexts has become a critical capability for modern large language models (LLMs). However, serving long-context LLMs comes with significant inference costs due to the high memory overhead of the key-value (KV) cache. Existing work leverages dynamic sparse attention algorithms (DSAes) to mitigate the KV cache overhead, but these algorithms rely on top-$k$ KV cache selection, which results in a trade-off between accuracy and efficiency. A larger $k$ improves accuracy but decreases efficiency, while a smaller $k$ boosts efficiency but compromises accuracy. To overcome this trade-off, this paper presents PSA, a $\underline{P}$rogressive $\underline{S}$parse $\underline{A}$ttention mechanism that integrates algorithmic innovations with system co-design to achieve both high inference accuracy and improved efficiency in LLM serving. The PSA algorithm adaptively adjusts the KV cache budget of different tokens and layers according to their real attention weight distributions, rather than relying on a fixed budget $k$. This enables high accuracy while minimizing KV cache usage. To further enhance execution efficiency, we introduce a pipelined iteration scheme that reduces CPU-GPU interleaving and synchronization overhead during PSA computation. Additionally, we implement unified GPU memory management that optimizes PSA's memory utilization by accounting for uneven memory requirements across different model layers. Extensive experimental results demonstrate that PSA reduces KV cache usage for attention computation by up to 2.4$\times$ and 8.8$\times$, and increases end-to-end serving throughput by up to 1.4$\times$ and 2.0$\times$, compared to state-of-the-art DSAes and systems without sparse attention, respectively.</description>
   <guid>oai:arXiv.org:2503.00392v1</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</rights>
   <creator>Qihui Zhou, Peiqi Yin, Pengfei Zuo, James Cheng</creator>
  </item>
  <item>
   <title>Safety Tax: Safety Alignment Makes Your Large Reasoning Models Less Reasonable</title>
   <link>https://arxiv.org/abs/2503.00555</link>
   <description>Safety alignment is an important procedure before the official deployment of a Large Language Model (LLM). While safety alignment has been extensively studied for LLM, there is still a large research gap for Large Reasoning Models (LRMs) that equip with improved reasoning capability. We in this paper systematically examine a simplified pipeline for producing safety aligned LRMs. With our evaluation of various LRMs, we deliver two main findings: i) Safety alignment can be done upon the LRM to restore its safety capability. ii) Safety alignment leads to a degradation of the reasoning capability of LRMs. The two findings show that there exists a trade-off between reasoning and safety capability with the sequential LRM production pipeline. The discovered trade-off, which we name Safety Tax, should shed light on future endeavors of safety research on LRMs. As a by-product, we curate a dataset called DirectRefusal, which might serve as an alternative dataset for safety alignment. Our source code is available at https://github.com/git-disl/Safety-Tax.</description>
   <guid>oai:arXiv.org:2503.00555v1</guid>
   <category>cs.CR</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim Furkan Tekin, Zachary Yahn, Yichang Xu, Ling Liu</creator>
  </item>
  <item>
   <title>PinLanding: Content-First Keyword Landing Page Generation via Multi-Modal AI for Web-Scale Discovery</title>
   <link>https://arxiv.org/abs/2503.00619</link>
   <description>Online platforms like Pinterest hosting vast content collections traditionally rely on manual curation or user-generated search logs to create keyword landing pages (KLPs) -- topic-centered collection pages that serve as entry points for content discovery. While manual curation ensures quality, it doesn't scale to millions of collections, and search log approaches result in limited topic coverage and imprecise content matching. In this paper, we present PinLanding, a novel content-first architecture that transforms the way platforms create topical collections. Instead of deriving topics from user behavior, our system employs a multi-stage pipeline combining vision-language model (VLM) for attribute extraction, large language model (LLM) for topic generation, and a CLIP-based dual-encoder architecture for precise content matching. Our model achieves 99.7% Recall@10 on Fashion200K benchmark, demonstrating strong attribute understanding capabilities. In production deployment for search engine optimization with 4.2 million shopping landing pages, the system achieves a 4X increase in topic coverage and 14.29% improvement in collection attribute precision over the traditional search log-based approach via human evaluation. The architecture can be generalized beyond search traffic to power various user experiences, including content discovery and recommendations, providing a scalable solution to transform unstructured content into curated topical collections across any content domain.</description>
   <guid>oai:arXiv.org:2503.00619v1</guid>
   <category>cs.IR</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Faye Zhang, Jasmine Wan, Qianyu Cheng, Jinfeng Rao</creator>
  </item>
  <item>
   <title>Efficiently Editing Mixture-of-Experts Models with Compressed Experts</title>
   <link>https://arxiv.org/abs/2503.00634</link>
   <description>Mixture-of-Experts (MoE) models have become a key approach for scaling large language models efficiently by activating only a subset of experts during training and inference. Typically, the number of activated experts presents a trade-off: fewer experts reduce computational costs, while more experts improve performance. Recent studies reveal that not all activated experts contribute equally to model performance, with some providing minimal utility, particularly when finetuning pretrained MoE models for specialized downstream tasks. The co-existence of significant and redundant parameters in experts provides us an opportunity to reduce the number of activated experts while maintaining model performance. In this work, we propose the concept of compressed experts, lightweight modules that serve as compact representations of full experts. Our approach preserves the most important experts while replacing other auxiliary activated experts with compressed experts. The reduction of active parameters significantly lowers inference costs while achieving comparable performance. Extensive experiments on models including Phi-MoE and OLMoE demonstrate that compressed experts recover over 90% of full expert performance across various tasks while reducing more than 30% active parameters and saving 20% in inference costs. This approach enables efficient deployment of MoE models in resource-constrained settings and facilitates scaling to larger models with manageable overhead. Our code is available at https://github.com/yifei-he/Compressed-Experts.</description>
   <guid>oai:arXiv.org:2503.00634v1</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Yifei He, Yang Liu, Chen Liang, Hany Hassan Awadalla</creator>
  </item>
  <item>
   <title>Towards Efficient Educational Chatbots: Benchmarking RAG Frameworks</title>
   <link>https://arxiv.org/abs/2503.00781</link>
   <description>Large Language Models (LLMs) have proven immensely beneficial in education by capturing vast amounts of literature-based information, allowing them to generate context without relying on external sources. In this paper, we propose a generative AI-powered GATE question-answering framework (GATE stands for Graduate Aptitude Test in Engineering) that leverages LLMs to explain GATE solutions and support students in their exam preparation. We conducted extensive benchmarking to select the optimal embedding model and LLM, evaluating our framework based on criteria such as latency, faithfulness, and relevance, with additional validation through human evaluation. Our chatbot integrates state-of-the-art embedding models and LLMs to deliver accurate, context-aware responses. Through rigorous experimentation, we identified configurations that balance performance and computational efficiency, ensuring a reliable chatbot to serve students' needs. Additionally, we discuss the challenges faced in data processing and modeling and implemented solutions. Our work explores the application of Retrieval-Augmented Generation (RAG) for GATE Q/A explanation tasks, and our findings demonstrate significant improvements in retrieval accuracy and response quality. This research offers practical insights for developing effective AI-driven educational tools while highlighting areas for future enhancement in usability and scalability.</description>
   <guid>oai:arXiv.org:2503.00781v1</guid>
   <category>cs.IR</category>
   <category>cs.AI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Umar Ali Khan, Ekram Khan, Fiza Khan, Athar Ali Moinuddin</creator>
  </item>
  <item>
   <title>Babel: Open Multilingual Large Language Models Serving Over 90% of Global Speakers</title>
   <link>https://arxiv.org/abs/2503.00865</link>
   <description>Large language models (LLMs) have revolutionized natural language processing (NLP), yet open-source multilingual LLMs remain scarce, with existing models often limited in language coverage. Such models typically prioritize well-resourced languages, while widely spoken but under-resourced languages are often overlooked. To address this disparity, we introduce $\texttt{Babel}$, an open multilingual LLM that covers the top 25 languages by number of speakers, supports over 90% of the global population, and includes many languages neglected by other open multilingual LLMs. Unlike traditional continue pretraining approaches, Babel expands its parameter count through a layer extension technique that elevates Babel's performance ceiling. We introduce two variants: $\texttt{Babel-9B}$, designed for efficient inference and fine-tuning, and $\texttt{Babel-83B}$, which sets a new standard for open multilingual LLMs. Extensive evaluations on multilingual tasks demonstrate its superior performance compared to open LLMs of comparable size. In addition, using open-source supervised fine-tuning datasets, Babel achieves remarkable performance, with Babel-9B-Chat leading among 10B-sized LLMs and Babel-83B-Chat setting a new standard for multilingual tasks, reaching the same level of commercial models.</description>
   <guid>oai:arXiv.org:2503.00865v1</guid>
   <category>cs.CL</category>
   <category>cs.AI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Yiran Zhao, Chaoqun Liu, Yue Deng, Jiahao Ying, Mahani Aljunied, Zhaodonghui Li, Lidong Bing, Hou Pong Chan, Yu Rong, Deli Zhao, Wenxuan Zhang</creator>
  </item>
  <item>
   <title>Same Question, Different Words: A Latent Adversarial Framework for Prompt Robustness</title>
   <link>https://arxiv.org/abs/2503.01345</link>
   <description>Insensitivity to semantically-preserving variations of prompts (paraphrases) is crucial for reliable behavior and real-world deployment of large language models. However, language models exhibit significant performance degradation when faced with semantically equivalent but differently phrased prompts, and existing solutions either depend on trial-and-error prompt engineering or require computationally expensive inference-time algorithms. In this study, built on the key insight that worst-case prompts exhibit a drift in embedding space, we present Latent Adversarial Paraphrasing (LAP), a dual-loop adversarial framework: the inner loop trains a learnable perturbation to serve as a &quot;latent continuous paraphrase&quot; while preserving semantics through Lagrangian regulation, and the outer loop optimizes the language model parameters on these perturbations. We conduct extensive experiments to demonstrate the effectiveness of LAP across multiple LLM architectures on the RobustAlpaca benchmark with a 0.5%-4% absolution improvement on worst-case win-rate compared with vanilla supervised fine-tuning.</description>
   <guid>oai:arXiv.org:2503.01345v1</guid>
   <category>cs.CL</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Tingchen Fu, Fazl Barez</creator>
  </item>
  <item>
   <title>MoCFL: Mobile Cluster Federated Learning Framework for Highly Dynamic Network</title>
   <link>https://arxiv.org/abs/2503.01557</link>
   <description>Frequent fluctuations of client nodes in highly dynamic mobile clusters can lead to significant changes in feature space distribution and data drift, posing substantial challenges to the robustness of existing federated learning (FL) strategies. To address these issues, we proposed a mobile cluster federated learning framework (MoCFL). MoCFL enhances feature aggregation by introducing an affinity matrix that quantifies the similarity between local feature extractors from different clients, addressing dynamic data distribution changes caused by frequent client churn and topology changes. Additionally, MoCFL integrates historical and current feature information when training the global classifier, effectively mitigating the catastrophic forgetting problem frequently encountered in mobile scenarios. This synergistic combination ensures that MoCFL maintains high performance and stability in dynamically changing mobile environments. Experimental results on the UNSW-NB15 dataset show that MoCFL excels in dynamic environments, demonstrating superior robustness and accuracy while maintaining reasonable training costs.</description>
   <guid>oai:arXiv.org:2503.01557v1</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Kai Fang, Jiangtao Deng, Chengzu Dong, Usman Naseem, Tongcun Liu, Hailin Feng, Wei Wang</creator>
  </item>
  <item>
   <title>AutoAdvExBench: Benchmarking autonomous exploitation of adversarial example defenses</title>
   <link>https://arxiv.org/abs/2503.01811</link>
   <description>We introduce AutoAdvExBench, a benchmark to evaluate if large language models (LLMs) can autonomously exploit defenses to adversarial examples. Unlike existing security benchmarks that often serve as proxies for real-world tasks, bench directly measures LLMs' success on tasks regularly performed by machine learning security experts. This approach offers a significant advantage: if a LLM could solve the challenges presented in bench, it would immediately present practical utility for adversarial machine learning researchers. We then design a strong agent that is capable of breaking 75% of CTF-like (&quot;homework exercise&quot;) adversarial example defenses. However, we show that this agent is only able to succeed on 13% of the real-world defenses in our benchmark, indicating the large gap between difficulty in attacking &quot;real&quot; code, and CTF-like code. In contrast, a stronger LLM that can attack 21% of real defenses only succeeds on 54% of CTF-like defenses. We make this benchmark available at https://github.com/ethz-spylab/AutoAdvExBench.</description>
   <guid>oai:arXiv.org:2503.01811v1</guid>
   <category>cs.CR</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Nicholas Carlini, Javier Rando, Edoardo Debenedetti, Milad Nasr, Florian Tram\`er</creator>
  </item>
  <item>
   <title>User Intent to Use DeepSeek for Healthcare Purposes and their Trust in the Large Language Model: Multinational Survey Study</title>
   <link>https://arxiv.org/abs/2502.17487</link>
   <description>Large language models (LLMs) increasingly serve as interactive healthcare resources, yet user acceptance remains underexplored. This study examines how ease of use, perceived usefulness, trust, and risk perception interact to shape intentions to adopt DeepSeek, an emerging LLM-based platform, for healthcare purposes. A cross-sectional survey of 556 participants from India, the United Kingdom, and the United States was conducted to measure perceptions and usage patterns. Structural equation modeling assessed both direct and indirect effects, including potential quadratic relationships. Results revealed that trust plays a pivotal mediating role: ease of use exerts a significant indirect effect on usage intentions through trust, while perceived usefulness contributes to both trust development and direct adoption. By contrast, risk perception negatively affects usage intent, emphasizing the importance of robust data governance and transparency. Notably, significant non-linear paths were observed for ease of use and risk, indicating threshold or plateau effects. The measurement model demonstrated strong reliability and validity, supported by high composite reliabilities, average variance extracted, and discriminant validity measures. These findings extend technology acceptance and health informatics research by illuminating the multifaceted nature of user adoption in sensitive domains. Stakeholders should invest in trust-building strategies, user-centric design, and risk mitigation measures to encourage sustained and safe uptake of LLMs in healthcare. Future work can employ longitudinal designs or examine culture-specific variables to further clarify how user perceptions evolve over time and across different regulatory environments. Such insights are critical for harnessing AI to enhance outcomes.</description>
   <guid>oai:arXiv.org:2502.17487v2</guid>
   <category>cs.AI</category>
   <category>cs.CY</category>
   <category>cs.HC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Avishek Choudhury, Yeganeh Shahsavar, Hamid Shamszare</creator>
  </item>
  <item>
   <title>Explainable Machine Learning-Based Security and Privacy Protection Framework for Internet of Medical Things Systems</title>
   <link>https://arxiv.org/abs/2403.09752</link>
   <description>The Internet of Medical Things (IoMT) transcends traditional medical boundaries, enabling a transition from reactive treatment to proactive prevention. This innovative method revolutionizes healthcare by facilitating early disease detection and tailored care, particularly in chronic disease management, where IoMT automates treatments based on real-time health data collection. Nonetheless, its benefits are countered by significant security challenges that endanger the lives of its users due to the sensitivity and value of the processed data, thereby attracting malicious interests. Moreover, the utilization of wireless communication for data transmission exposes medical data to interception and tampering by cybercriminals. Additionally, anomalies may arise due to human error, network interference, or hardware malfunctions. In this context, anomaly detection based on Machine Learning (ML) is an interesting solution, but it comes up against obstacles in terms of explicability and privacy protection. To address these challenges, a new framework for Intrusion Detection Systems is introduced, leveraging Artificial Neural Networks for intrusion detection while utilizing Federated Learning (FL) for privacy preservation. Additionally, eXplainable Artificial Intelligence methods are incorporated to enhance model explanation and interpretation. The efficacy of the proposed framework is evaluated and compared with centralized approaches using multiple datasets containing network and medical data, simulating various attack types impacting the confidentiality, integrity, and availability of medical and physiological data. The results obtained offer compelling evidence that the FL method performs comparably to the centralized method, demonstrating high performance. Additionally, it affords the dual advantage of safeguarding privacy and providing model explanation while adhering to ethical principles.</description>
   <guid>oai:arXiv.org:2403.09752v2</guid>
   <category>cs.CR</category>
   <category>cs.AI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</rights>
   <creator>Ayoub Si-ahmed, Mohammed Ali Al-Garadi, Narhimene Boustia</creator>
  </item>
  <item>
   <title>Language Guided Skill Discovery</title>
   <link>https://arxiv.org/abs/2406.06615</link>
   <description>Skill discovery methods enable agents to learn diverse emergent behaviors without explicit rewards. To make learned skills useful for unknown downstream tasks, obtaining a semantically diverse repertoire of skills is essential. While some approaches introduce a discriminator to distinguish skills and others aim to increase state coverage, no existing work directly addresses the &quot;semantic diversity&quot; of skills. We hypothesize that leveraging the semantic knowledge of large language models (LLMs) can lead us to improve semantic diversity of resulting behaviors. In this sense, we introduce Language Guided Skill Discovery (LGSD), a skill discovery framework that aims to directly maximize the semantic diversity between skills. LGSD takes user prompts as input and outputs a set of semantically distinctive skills. The prompts serve as a means to constrain the search space into a semantically desired subspace, and the generated LLM outputs guide the agent to visit semantically diverse states within the subspace. We demonstrate that LGSD enables legged robots to visit different user-intended areas on a plane by simply changing the prompt. Furthermore, we show that language guidance aids in discovering more diverse skills compared to five existing skill discovery methods in robot-arm manipulation environments. Lastly, LGSD provides a simple way of utilizing learned skills via natural language.</description>
   <guid>oai:arXiv.org:2406.06615v2</guid>
   <category>cs.CL</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <category>cs.RO</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Seungeun Rho, Laura Smith, Tianyu Li, Sergey Levine, Xue Bin Peng, Sehoon Ha</creator>
  </item>
  <item>
   <title>Semantic Operators: A Declarative Model for Rich, AI-based Data Processing</title>
   <link>https://arxiv.org/abs/2407.11418</link>
   <description>The semantic capabilities of large language models (LLMs) have the potential to enable rich analytics and reasoning over vast knowledge corpora. Unfortunately, existing systems either empirically optimize expensive LLM-powered operations with no performance guarantees, or serve a limited set of row-wise LLM operations, providing limited robustness, expressiveness and usability. We introduce semantic operators, the first formalism for declarative and general-purpose AI-based transformations based on natural language specifications (e.g., filtering, sorting, joining or aggregating records using natural language criteria). Each operator opens a rich space for execution plans, similar to relational operators. Our model specifies the expected behavior of each operator with a high-quality gold algorithm, and we develop an optimization framework that reduces cost, while providing accuracy guarantees with respect to a gold algorithm. Using this approach, we propose several novel optimizations to accelerate semantic filtering, joining, group-by and top-k operations by up to $1,000\times$. We implement semantic operators in the LOTUS system and demonstrate LOTUS' effectiveness on real, bulk-semantic processing applications, including fact-checking, biomedical multi-label classification, search, and topic analysis. We show that the semantic operator model is expressive, capturing state-of-the-art AI pipelines in a few operator calls, and making it easy to express new pipelines that match or exceed quality of recent LLM-based analytic systems by up to $170\%$, while offering accuracy guarantees. Overall, LOTUS programs match or exceed the accuracy of state-of-the-art AI pipelines for each task while running up to $3.6\times$ faster than the highest-quality baselines. LOTUS is publicly available at https://github.com/lotus-data/lotus.</description>
   <guid>oai:arXiv.org:2407.11418v3</guid>
   <category>cs.DB</category>
   <category>cs.AI</category>
   <category>cs.CL</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Liana Patel, Siddharth Jha, Melissa Pan, Harshit Gupta, Parth Asawa, Carlos Guestrin, Matei Zaharia</creator>
  </item>
  <item>
   <title>StarVid: Enhancing Semantic Alignment in Video Diffusion Models via Spatial and SynTactic Guided Attention Refocusing</title>
   <link>https://arxiv.org/abs/2409.15259</link>
   <description>Recent advances in text-to-video (T2V) generation with diffusion models have garnered significant attention. However, they typically perform well in scenes with a single object and motion, struggling in compositional scenarios with multiple objects and distinct motions to accurately reflect the semantic content of text prompts. To address these challenges, we propose \textbf{StarVid}, a plug-and-play, training-free method that improves semantic alignment between multiple subjects, their motions, and text prompts in T2V models. StarVid first leverages the spatial reasoning capabilities of large language models (LLMs) for two-stage motion trajectory planning based on text prompts. Such trajectories serve as spatial priors, guiding a spatial-aware loss to refocus cross-attention (CA) maps into distinctive regions. Furthermore, we propose a syntax-guided contrastive constraint to strengthen the correlation between the CA maps of verbs and their corresponding nouns, enhancing motion-subject binding. Both qualitative and quantitative evaluations demonstrate that the proposed framework significantly outperforms baseline methods, delivering videos of higher quality with improved semantic consistency.</description>
   <guid>oai:arXiv.org:2409.15259v2</guid>
   <category>cs.CV</category>
   <category>cs.AI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Yuanhang Li, Qi Mao, Lan Chen, Zhen Fang, Lei Tian, Xinyan Xiao, Libiao Jin, Hua Wu</creator>
  </item>
  <item>
   <title>Federated Learning in Practice: Reflections and Projections</title>
   <link>https://arxiv.org/abs/2410.08892</link>
   <description>Federated Learning (FL) is a machine learning technique that enables multiple entities to collaboratively learn a shared model without exchanging their local data. Over the past decade, FL systems have achieved substantial progress, scaling to millions of devices across various learning domains while offering meaningful differential privacy (DP) guarantees. Production systems from organizations like Google, Apple, and Meta demonstrate the real-world applicability of FL. However, key challenges remain, including verifying server-side DP guarantees and coordinating training across heterogeneous devices, limiting broader adoption. Additionally, emerging trends such as large (multi-modal) models and blurred lines between training, inference, and personalization challenge traditional FL frameworks. In response, we propose a redefined FL framework that prioritizes privacy principles rather than rigid definitions. We also chart a path forward by leveraging trusted execution environments and open-source ecosystems to address these challenges and facilitate future advancements in FL.</description>
   <guid>oai:arXiv.org:2410.08892v2</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <category>cs.CR</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Katharine Daly, Hubert Eichner, Peter Kairouz, H. Brendan McMahan, Daniel Ramage, Zheng Xu</creator>
  </item>
  <item>
   <title>Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models</title>
   <link>https://arxiv.org/abs/2501.14406</link>
   <description>Pre-trained Language Models (PLMs) have demonstrated their superiority and versatility in modern Natural Language Processing (NLP), effectively adapting to various downstream tasks through further fine-tuning. Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution to address privacy and efficiency challenges in distributed training for PLMs on resource-constrained local devices. However, our measurements reveal two key limitations of FedPEFT: heterogeneous data across devices leads to significant performance degradation, and a fixed parameter configuration results in communication inefficiency. To overcome these limitations, we propose FedARA, a novel Adaptive Rank Allocation framework for federated parameter-efficient fine-tuning of language models. Specifically, FedARA employs truncated Singular Value Decomposition (SVD) adaptation to enhance similar feature representation across clients, significantly mitigating the adverse effects of data heterogeneity. Subsequently, it utilizes dynamic rank allocation to progressively identify critical ranks, effectively improving communication efficiency. Lastly, it leverages rank-based module pruning to automatically remove inactive modules, steadily reducing local computational cost and memory usage in each federated learning round. Extensive experiments show that FedARA consistently outperforms baselines by an average of 6.95% to 8.49% across various datasets and models under heterogeneous data while significantly improving communication efficiency by 2.40$ \times$. Moreover, experiments on various edge devices demonstrate substantial decreases in total training time and energy consumption by up to 48.90% and 46.95%, respectively.</description>
   <guid>oai:arXiv.org:2501.14406v2</guid>
   <category>cs.DC</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <category>cs.NI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Fei Wu, Jia Hu, Geyong Min, Shiqiang Wang</creator>
  </item>
  <item>
   <title>Modification and Generated-Text Detection: Achieving Dual Detection Capabilities for the Outputs of LLM by Watermark</title>
   <link>https://arxiv.org/abs/2502.08332</link>
   <description>The development of large language models (LLMs) has raised concerns about potential misuse. One practical solution is to embed a watermark in the text, allowing ownership verification through watermark extraction. Existing methods primarily focus on defending against modification attacks, often neglecting other spoofing attacks. For example, attackers can alter the watermarked text to produce harmful content without compromising the presence of the watermark, which could lead to false attribution of this malicious content to the LLM. This situation poses a serious threat to the LLMs service providers and highlights the significance of achieving modification detection and generated-text detection simultaneously. Therefore, we propose a technique to detect modifications in text for unbiased watermark which is sensitive to modification. We introduce a new metric called ``discarded tokens&quot;, which measures the number of tokens not included in watermark detection. When a modification occurs, this metric changes and can serve as evidence of the modification. Additionally, we improve the watermark detection process and introduce a novel method for unbiased watermark. Our experiments demonstrate that we can achieve effective dual detection capabilities: modification detection and generated-text detection by watermark.</description>
   <guid>oai:arXiv.org:2502.08332v2</guid>
   <category>cs.CR</category>
   <category>cs.AI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</rights>
   <creator>Yuhang Cai, Yaofei Wang, Donghui Hu, Chen Gu</creator>
  </item>
  <item>
   <title>Semantic Operators: A Declarative Model for Rich, AI-based Data Processing</title>
   <link>https://arxiv.org/abs/2407.11418</link>
   <description>The semantic capabilities of large language models (LLMs) have the potential to enable rich analytics and reasoning over vast knowledge corpora. Unfortunately, existing systems either empirically optimize expensive LLM-powered operations with no performance guarantees, or serve a limited set of row-wise LLM operations, providing limited robustness, expressiveness and usability. We introduce semantic operators, the first formalism for declarative and general-purpose AI-based transformations based on natural language specifications (e.g., filtering, sorting, joining or aggregating records using natural language criteria). Each operator opens a rich space for execution plans, similar to relational operators. Our model specifies the expected behavior of each operator with a high-quality gold algorithm, and we develop an optimization framework that reduces cost, while providing accuracy guarantees with respect to a gold algorithm. Using this approach, we propose several novel optimizations to accelerate semantic filtering, joining, group-by and top-k operations by up to $1,000\times$. We implement semantic operators in the LOTUS system and demonstrate LOTUS' effectiveness on real, bulk-semantic processing applications, including fact-checking, biomedical multi-label classification, search, and topic analysis. We show that the semantic operator model is expressive, capturing state-of-the-art AI pipelines in a few operator calls, and making it easy to express new pipelines that match or exceed quality of recent LLM-based analytic systems by up to $170\%$, while offering accuracy guarantees. Overall, LOTUS programs match or exceed the accuracy of state-of-the-art AI pipelines for each task while running up to $3.6\times$ faster than the highest-quality baselines. LOTUS is publicly available at https://github.com/lotus-data/lotus.</description>
   <guid>oai:arXiv.org:2407.11418v3</guid>
   <category>cs.DB</category>
   <category>cs.AI</category>
   <category>cs.CL</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Liana Patel, Siddharth Jha, Melissa Pan, Harshit Gupta, Parth Asawa, Carlos Guestrin, Matei Zaharia</creator>
  </item>
  <item>
   <title>HLoRA: Efficient Federated Learning System for LLM Heterogeneous Fine-Tuning</title>
   <link>https://arxiv.org/abs/2503.00813</link>
   <description>Federated learning systems have been identified as an efficient approach to scaling distributed model training with a large amount of participants or data owners while guaranteeing data privacy. To apply the current most popular pre-trained large language models to other domains with data privacy guarantee requirements, existing works propose fine-tuning the pre-trained large language models in federated learning environments across data owners using the parameter efficient fine-tuning approaches, LoRA. To address the resource and data heterogeneous issues for the participants, previous works adopted heterogeneous LoRA using different ranks for different clients and pending their rank, which brings bias for the parameter aggregation.
  To address this issue, we propose HLoRA, an efficient federated learning system utilizing a modified LoRA approach that incorporates rank heterogeneity to optimize communication and computational efficiency. Experimental results, conducted using the Microsoft Research Paraphrase Corpus (MRPC), Quora Question Pairs (QQP) and Recognizing Textual Entailment (RTE), within the Plato federated learning framework, demonstrate that our method not only reduces resource demands but also outperforms traditional LoRA applications in terms of convergence speed and final model accuracy. This study shows that our approach can significantly improve the practical deployment of federated LLM fine-tuning, particularly in environments with diverse client resources.</description>
   <guid>oai:arXiv.org:2503.00813v1</guid>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</rights>
   <creator>Qianli Liu, Zhaorui Zhang, Xin Yao, Benben Liu</creator>
  </item>
  <item>
   <title>FLStore: Efficient Federated Learning Storage for non-training workloads</title>
   <link>https://arxiv.org/abs/2503.00323</link>
   <description>Federated Learning (FL) is an approach for privacy-preserving Machine Learning (ML), enabling model training across multiple clients without centralized data collection. With an aggregator server coordinating training, aggregating model updates, and storing metadata across rounds. In addition to training, a substantial part of FL systems are the non-training workloads such as scheduling, personalization, clustering, debugging, and incentivization. Most existing systems rely on the aggregator to handle non-training workloads and use cloud services for data storage. This results in high latency and increased costs as non-training workloads rely on large volumes of metadata, including weight parameters from client updates, hyperparameters, and aggregated updates across rounds, making the situation even worse. We propose FLStore, a serverless framework for efficient FL non-training workloads and storage. FLStore unifies the data and compute planes on a serverless cache, enabling locality-aware execution via tailored caching policies to reduce latency and costs. Per our evaluations, compared to cloud object store based aggregator server FLStore reduces per request average latency by 71% and costs by 92.45%, with peak improvements of 99.7% and 98.8%, respectively. Compared to an in-memory cloud cache based aggregator server, FLStore reduces average latency by 64.6% and costs by 98.83%, with peak improvements of 98.8% and 99.6%, respectively. FLStore integrates seamlessly with existing FL frameworks with minimal modifications, while also being fault-tolerant and highly scalable.</description>
   <guid>oai:arXiv.org:2503.00323v1</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Ahmad Faraz Khan, Samuel Fountain, Ahmed M. Abdelmoniem, Ali R. Butt, Ali Anwar</creator>
  </item>
  <item>
   <title>Conditioning on Local Statistics for Scalable Heterogeneous Federated Learning</title>
   <link>https://arxiv.org/abs/2503.00378</link>
   <description>Federated learning is a distributed machine learning approach where multiple clients collaboratively train a model without sharing their local data, which contributes to preserving privacy. A challenge in federated learning is managing heterogeneous data distributions across clients, which can hinder model convergence and performance due to the need for the global model to generalize well across diverse local datasets. We propose to use local characteristic statistics, by which we mean some statistical properties calculated independently by each client using only their local training dataset. These statistics, such as means, covariances, and higher moments, are used to capture the characteristics of the local data distribution. They are not shared with other clients or a central node. During training, these local statistics help the model learn how to condition on the local data distribution, and during inference, they guide the client's predictions. Our experiments show that this approach allows for efficient handling of heterogeneous data across the federation, has favorable scaling compared to approaches that directly try to identify peer nodes that share distribution characteristics, and maintains privacy as no additional information needs to be communicated.</description>
   <guid>oai:arXiv.org:2503.00378v1</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <category>cs.CR</category>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Rickard Br\&quot;annvall</creator>
  </item>
  <item>
   <title>Asynchronous Personalized Federated Learning through Global Memorization</title>
   <link>https://arxiv.org/abs/2503.00407</link>
   <description>The proliferation of Internet of Things devices and advances in communication technology have unleashed an explosion of personal data, amplifying privacy concerns amid stringent regulations like GDPR and CCPA. Federated Learning offers a privacy preserving solution by enabling collaborative model training across decentralized devices without centralizing sensitive data. However, statistical heterogeneity from non-independent and identically distributed datasets and system heterogeneity due to client dropouts particularly those with monopolistic classes severely degrade the global model's performance. To address these challenges, we propose the Asynchronous Personalized Federated Learning framework, which empowers clients to develop personalized models using a server side semantic generator. This generator, trained via data free knowledge transfer under global model supervision, enhances client data diversity by producing both seen and unseen samples, the latter enabled by Zero-Shot Learning to mitigate dropout-induced data loss. To counter the risks of synthetic data impairing training, we introduce a decoupled model interpolation method, ensuring robust personalization. Extensive experiments demonstrate that AP FL significantly outperforms state of the art FL methods in tackling non-IID distributions and client dropouts, achieving superior accuracy and resilience across diverse real-world scenarios.</description>
   <guid>oai:arXiv.org:2503.00407v1</guid>
   <category>cs.LG</category>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Fan Wan, Yuchen Li, Xueqi Qiu, Rui Sun, Leyuan Zhang, Xingyu Miao, Tianyu Zhang, Haoran Duan, Yang Long</creator>
  </item>
  <item>
   <title>Communication-Efficient Device Scheduling for Federated Learning Using Lyapunov Optimization</title>
   <link>https://arxiv.org/abs/2503.00569</link>
   <description>Federated learning (FL) is a useful tool that enables the training of machine learning models over distributed data without having to collect data centrally. When deploying FL in constrained wireless environments, however, intermittent connectivity of devices, heterogeneous connection quality, and non-i.i.d. data can severely slow convergence. In this paper, we consider FL with arbitrary device participation probabilities for each round and show that by weighing each device's update by the reciprocal of their per-round participation probability, we can guarantee convergence to a stationary point. Our bound applies to non-convex loss functions and non-i.i.d. datasets and recovers state-of-the-art convergence rates for both full and uniform partial participation, including linear speedup, with only a single-sided learning rate. Then, using the derived convergence bound, we develop a new online client selection and power allocation algorithm that utilizes the Lyapunov drift-plus-penalty framework to opportunistically minimize a function of the convergence bound and the average communication time under a transmit power constraint. We use optimization over manifold techniques to obtain a solution to the minimization problem. Thanks to the Lyapunov framework, one key feature of the algorithm is that knowledge of the channel distribution is not required and only the instantaneous channel state information needs to be known. Using the CIFAR-10 dataset with varying levels of data heterogeneity, we show through simulations that the communication time can be significantly decreased using our algorithm compared to uniformly random participation, especially for heterogeneous channel conditions.</description>
   <guid>oai:arXiv.org:2503.00569v1</guid>
   <category>cs.LG</category>
   <category>cs.DC</category>
   <category>stat.ML</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Jake B. Perazzone, Shiqiang Wang, Mingyue Ji, Kevin Chan</creator>
  </item>
  <item>
   <title>GRAIN: Exact Graph Reconstruction from Gradients</title>
   <link>https://arxiv.org/abs/2503.01838</link>
   <description>Federated learning claims to enable collaborative model training among multiple clients with data privacy by transmitting gradient updates instead of the actual client data. However, recent studies have shown the client privacy is still at risk due to the, so called, gradient inversion attacks which can precisely reconstruct clients' text and image data from the shared gradient updates. While these attacks demonstrate severe privacy risks for certain domains and architectures, the vulnerability of other commonly-used data types, such as graph-structured data, remain under-explored. To bridge this gap, we present GRAIN, the first exact gradient inversion attack on graph data in the honest-but-curious setting that recovers both the structure of the graph and the associated node features. Concretely, we focus on Graph Convolutional Networks (GCN) and Graph Attention Networks (GAT) -- two of the most widely used frameworks for learning on graphs. Our method first utilizes the low-rank structure of GNN gradients to efficiently reconstruct and filter the client subgraphs which are then joined to complete the input graph. We evaluate our approach on molecular, citation, and social network datasets using our novel metric. We show that GRAIN reconstructs up to 80% of all graphs exactly, significantly outperforming the baseline, which achieves up to 20% correctly positioned nodes.</description>
   <guid>oai:arXiv.org:2503.01838v1</guid>
   <category>cs.LG</category>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by-sa/4.0/</rights>
   <creator>Maria Drencheva, Ivo Petrov, Maximilian Baader, Dimitar I. Dimitrov, Martin Vechev</creator>
  </item>
  <item>
   <title>Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models</title>
   <link>https://arxiv.org/abs/2501.14406</link>
   <description>Pre-trained Language Models (PLMs) have demonstrated their superiority and versatility in modern Natural Language Processing (NLP), effectively adapting to various downstream tasks through further fine-tuning. Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution to address privacy and efficiency challenges in distributed training for PLMs on resource-constrained local devices. However, our measurements reveal two key limitations of FedPEFT: heterogeneous data across devices leads to significant performance degradation, and a fixed parameter configuration results in communication inefficiency. To overcome these limitations, we propose FedARA, a novel Adaptive Rank Allocation framework for federated parameter-efficient fine-tuning of language models. Specifically, FedARA employs truncated Singular Value Decomposition (SVD) adaptation to enhance similar feature representation across clients, significantly mitigating the adverse effects of data heterogeneity. Subsequently, it utilizes dynamic rank allocation to progressively identify critical ranks, effectively improving communication efficiency. Lastly, it leverages rank-based module pruning to automatically remove inactive modules, steadily reducing local computational cost and memory usage in each federated learning round. Extensive experiments show that FedARA consistently outperforms baselines by an average of 6.95% to 8.49% across various datasets and models under heterogeneous data while significantly improving communication efficiency by 2.40$ \times$. Moreover, experiments on various edge devices demonstrate substantial decreases in total training time and energy consumption by up to 48.90% and 46.95%, respectively.</description>
   <guid>oai:arXiv.org:2501.14406v2</guid>
   <category>cs.DC</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <category>cs.NI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Fei Wu, Jia Hu, Geyong Min, Shiqiang Wang</creator>
  </item>
  <item>
   <title>Analytic Personalized Federated Meta-Learning</title>
   <link>https://arxiv.org/abs/2502.06915</link>
   <description>Analytic Federated Learning (AFL) is an enhanced gradient-free federated learning (FL) paradigm designed to accelerate training by updating the global model in a single step with closed-form least-square (LS) solutions. However, the obtained global model suffers performance degradation across clients with heterogeneous data distribution. Meta-learning is a common approach to tackle this problem by delivering personalized local models for individual clients. Yet, integrating meta-learning with AFL presents significant challenges: First, conventional AFL frameworks cannot support deep neural network (DNN) training which can influence the fast adaption capability of meta-learning for complex FL tasks. Second, the existing meta-learning method requires gradient information, which is not involved in AFL. To overcome the first challenge, we propose an AFL framework, namely FedACnnL, in which a layer-wise DNN collaborative training method is designed by modeling the training of each layer as a distributed LS problem. For the second challenge, we further propose an analytic personalized federated meta-learning framework, namely pFedACnnL. It generates a personalized model for each client by analytically solving a local objective which bridges the gap between the global model and the individual data distribution. FedACnnL is theoretically proven to require significantly shorter training time than the conventional FL frameworks on DNN training while the reduction ratio is $83\%\sim99\%$ in the experiment. Meanwhile, pFedACnnL excels at test accuracy with the vanilla FedACnnL by $4\%\sim8\%$ and it achieves state-of-the-art (SOTA) model performance in most cases of convex and non-convex settings compared with previous SOTA frameworks.</description>
   <guid>oai:arXiv.org:2502.06915v2</guid>
   <category>cs.DC</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Shunxian Gu, Chaoqun You, Deke Guo, Zhihao Qu, Bangbang Ren, Zaipeng Xie, Lailong Luo</creator>
  </item>
  <item>
   <title>pFedLVM: A Large Vision Model (LVM)-Driven and Latent Feature-Based Personalized Federated Learning Framework in Autonomous Driving</title>
   <link>https://arxiv.org/abs/2405.04146</link>
   <description>Deep learning-based Autonomous Driving (AD) models often exhibit poor generalization due to data heterogeneity in an ever domain-shifting environment. While Federated Learning (FL) could improve the generalization of an AD model (known as FedAD system), conventional models often struggle with under-fitting as the amount of accumulated training data progressively increases. To address this issue, instead of conventional small models, employing Large Vision Models (LVMs) in FedAD is a viable option for better learning of representations from a vast volume of data. However, implementing LVMs in FedAD introduces three challenges: (I) the extremely high communication overheads associated with transmitting LVMs between participating vehicles and a central server; (II) lack of computing resource to deploy LVMs on each vehicle; (III) the performance drop due to LVM focusing on shared features but overlooking local vehicle characteristics. To overcome these challenges, we propose pFedLVM, a LVM-Driven, Latent Feature-Based Personalized Federated Learning framework. In this approach, the LVM is deployed only on central server, which effectively alleviates the computational burden on individual vehicles. Furthermore, the exchange between central server and vehicles are the learned features rather than the LVM parameters, which significantly reduces communication overhead. In addition, we utilize both shared features from all participating vehicles and individual characteristics from each vehicle to establish a personalized learning mechanism. This enables each vehicle's model to learn features from others while preserving its personalized characteristics, thereby outperforming globally shared models trained in general FL. Extensive experiments demonstrate that pFedLVM outperforms the existing state-of-the-art approaches.</description>
   <guid>oai:arXiv.org:2405.04146v3</guid>
   <category>cs.RO</category>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</rights>
   <creator>Wei-Bin Kou, Qingfeng Lin, Ming Tang, Sheng Xu, Rongguang Ye, Yang Leng, Shuai Wang, Guofa Li, Zhenyu Chen, Guangxu Zhu, Yik-Chung Wu</creator>
  </item>
  <item>
   <title>Where is the Testbed for my Federated Learning Research?</title>
   <link>https://arxiv.org/abs/2407.14154</link>
   <description>Progressing beyond centralized AI is of paramount importance, yet, distributed AI solutions, in particular various federated learning (FL) algorithms, are often not comprehensively assessed, which prevents the research community from identifying the most promising approaches and practitioners from being convinced that a certain solution is deployment-ready. The largest hurdle towards FL algorithm evaluation is the difficulty of conducting real-world experiments over a variety of FL client devices and different platforms, with different datasets and data distribution, all while assessing various dimensions of algorithm performance, such as inference accuracy, energy consumption, and time to convergence, to name a few. In this paper, we present CoLExT, a real-world testbed for FL research. CoLExT is designed to streamline experimentation with custom FL algorithms in a rich testbed configuration space, with a large number of heterogeneous edge devices, ranging from single-board computers to smartphones, and provides real-time collection and visualization of a variety of metrics through automatic instrumentation. According to our evaluation, porting FL algorithms to CoLExT requires minimal involvement from the developer, and the instrumentation introduces minimal resource usage overhead. Furthermore, through an initial investigation involving popular FL algorithms running on CoLExT, we reveal previously unknown trade-offs, inefficiencies, and programming bugs.</description>
   <guid>oai:arXiv.org:2407.14154v2</guid>
   <category>cs.LG</category>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Janez Bo\v{z}i\v{c}, Am\^andio R. Faustino, Boris Radovi\v{c}, Marco Canini, Veljko Pejovi\'c</creator>
  </item>
  <item>
   <title>FedBiP: Heterogeneous One-Shot Federated Learning with Personalized Latent Diffusion Models</title>
   <link>https://arxiv.org/abs/2410.04810</link>
   <description>One-Shot Federated Learning (OSFL), a special decentralized machine learning paradigm, has recently gained significant attention. OSFL requires only a single round of client data or model upload, which reduces communication costs and mitigates privacy threats compared to traditional FL. Despite these promising prospects, existing methods face challenges due to client data heterogeneity and limited data quantity when applied to real-world OSFL systems. Recently, Latent Diffusion Models (LDM) have shown remarkable advancements in synthesizing high-quality images through pretraining on large-scale datasets, thereby presenting a potential solution to overcome these issues. However, directly applying pretrained LDM to heterogeneous OSFL results in significant distribution shifts in synthetic data, leading to performance degradation in classification models trained on such data. This issue is particularly pronounced in rare domains, such as medical imaging, which are underrepresented in LDM's pretraining data. To address this challenge, we propose Federated Bi-Level Personalization (FedBiP), which personalizes the pretrained LDM at both instance-level and concept-level. Hereby, FedBiP synthesizes images following the client's local data distribution without compromising the privacy regulations. FedBiP is also the first approach to simultaneously address feature space heterogeneity and client data scarcity in OSFL. Our method is validated through extensive experiments on three OSFL benchmarks with feature space heterogeneity, as well as on challenging medical and satellite image datasets with label heterogeneity. The results demonstrate the effectiveness of FedBiP, which substantially outperforms other OSFL methods.</description>
   <guid>oai:arXiv.org:2410.04810v2</guid>
   <category>cs.LG</category>
   <category>cs.CV</category>
   <category>cs.DC</category>
   <category>cs.MM</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Haokun Chen, Hang Li, Yao Zhang, Jinhe Bi, Gengyuan Zhang, Yueqi Zhang, Philip Torr, Jindong Gu, Denis Krompass, Volker Tresp</creator>
  </item>
  <item>
   <title>Fed-KAN: Federated Learning with Kolmogorov-Arnold Networks for Traffic Prediction</title>
   <link>https://arxiv.org/abs/2503.00154</link>
   <description>Non-Terrestrial Networks (NTNs) are becoming a critical component of modern communication infrastructures, especially with the advent of Low Earth Orbit (LEO) satellite systems. Traditional centralized learning approaches face major challenges in such networks due to high latency, intermittent connectivity and limited bandwidth. Federated Learning (FL) is a promising alternative as it enables decentralized training while maintaining data privacy. However, existing FL models, such as Federated Learning with Multi-Layer Perceptrons (Fed-MLP), can struggle with high computational complexity and poor adaptability to dynamic NTN environments. This paper provides a detailed analysis for Federated Learning with Kolmogorov-Arnold Networks (Fed-KAN), its implementation and performance improvements over traditional FL models in NTN environments for traffic forecasting. The proposed Fed-KAN is a novel approach that utilises the functional approximation capabilities of KANs in a FL framework. We evaluate Fed-KAN compared to Fed-MLP on a traffic dataset of real satellite operator and show a significant reduction in training and test loss. Our results show that Fed-KAN can achieve a 77.39% reduction in average test loss compared to Fed-MLP, highlighting its improved performance and better generalization ability. At the end of the paper, we also discuss some potential applications of Fed-KAN within O-RAN and Fed-KAN usage for split functionalities in NTN architecture.</description>
   <guid>oai:arXiv.org:2503.00154v1</guid>
   <category>cs.NI</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Engin Zeydan, Cristian J. Vaca-Rubio, Luis Blanco, Roberto Pereira, Marius Caus, Kapal Dev</creator>
  </item>
  <item>
   <title>Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models</title>
   <link>https://arxiv.org/abs/2501.14406</link>
   <description>Pre-trained Language Models (PLMs) have demonstrated their superiority and versatility in modern Natural Language Processing (NLP), effectively adapting to various downstream tasks through further fine-tuning. Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution to address privacy and efficiency challenges in distributed training for PLMs on resource-constrained local devices. However, our measurements reveal two key limitations of FedPEFT: heterogeneous data across devices leads to significant performance degradation, and a fixed parameter configuration results in communication inefficiency. To overcome these limitations, we propose FedARA, a novel Adaptive Rank Allocation framework for federated parameter-efficient fine-tuning of language models. Specifically, FedARA employs truncated Singular Value Decomposition (SVD) adaptation to enhance similar feature representation across clients, significantly mitigating the adverse effects of data heterogeneity. Subsequently, it utilizes dynamic rank allocation to progressively identify critical ranks, effectively improving communication efficiency. Lastly, it leverages rank-based module pruning to automatically remove inactive modules, steadily reducing local computational cost and memory usage in each federated learning round. Extensive experiments show that FedARA consistently outperforms baselines by an average of 6.95% to 8.49% across various datasets and models under heterogeneous data while significantly improving communication efficiency by 2.40$ \times$. Moreover, experiments on various edge devices demonstrate substantial decreases in total training time and energy consumption by up to 48.90% and 46.95%, respectively.</description>
   <guid>oai:arXiv.org:2501.14406v2</guid>
   <category>cs.DC</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <category>cs.NI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Fei Wu, Jia Hu, Geyong Min, Shiqiang Wang</creator>
  </item>
  <item>
   <title>FLAME: A Federated Learning Benchmark for Robotic Manipulation</title>
   <link>https://arxiv.org/abs/2503.01729</link>
   <description>Recent progress in robotic manipulation has been fueled by large-scale datasets collected across diverse environments. Training robotic manipulation policies on these datasets is traditionally performed in a centralized manner, raising concerns regarding scalability, adaptability, and data privacy. While federated learning enables decentralized, privacy-preserving training, its application to robotic manipulation remains largely unexplored. We introduce FLAME (Federated Learning Across Manipulation Environments), the first benchmark designed for federated learning in robotic manipulation. FLAME consists of: (i) a set of large-scale datasets of over 160,000 expert demonstrations of multiple manipulation tasks, collected across a wide range of simulated environments; (ii) a training and evaluation framework for robotic policy learning in a federated setting. We evaluate standard federated learning algorithms in FLAME, showing their potential for distributed policy learning and highlighting key challenges. Our benchmark establishes a foundation for scalable, adaptive, and privacy-aware robotic learning.</description>
   <guid>oai:arXiv.org:2503.01729v1</guid>
   <category>cs.RO</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Santiago Bou Betran, Alberta Longhini, Miguel Vasco, Yuchong Zhang, Danica Kragic</creator>
  </item>
  <item>
   <title>pFedLVM: A Large Vision Model (LVM)-Driven and Latent Feature-Based Personalized Federated Learning Framework in Autonomous Driving</title>
   <link>https://arxiv.org/abs/2405.04146</link>
   <description>Deep learning-based Autonomous Driving (AD) models often exhibit poor generalization due to data heterogeneity in an ever domain-shifting environment. While Federated Learning (FL) could improve the generalization of an AD model (known as FedAD system), conventional models often struggle with under-fitting as the amount of accumulated training data progressively increases. To address this issue, instead of conventional small models, employing Large Vision Models (LVMs) in FedAD is a viable option for better learning of representations from a vast volume of data. However, implementing LVMs in FedAD introduces three challenges: (I) the extremely high communication overheads associated with transmitting LVMs between participating vehicles and a central server; (II) lack of computing resource to deploy LVMs on each vehicle; (III) the performance drop due to LVM focusing on shared features but overlooking local vehicle characteristics. To overcome these challenges, we propose pFedLVM, a LVM-Driven, Latent Feature-Based Personalized Federated Learning framework. In this approach, the LVM is deployed only on central server, which effectively alleviates the computational burden on individual vehicles. Furthermore, the exchange between central server and vehicles are the learned features rather than the LVM parameters, which significantly reduces communication overhead. In addition, we utilize both shared features from all participating vehicles and individual characteristics from each vehicle to establish a personalized learning mechanism. This enables each vehicle's model to learn features from others while preserving its personalized characteristics, thereby outperforming globally shared models trained in general FL. Extensive experiments demonstrate that pFedLVM outperforms the existing state-of-the-art approaches.</description>
   <guid>oai:arXiv.org:2405.04146v3</guid>
   <category>cs.RO</category>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</rights>
   <creator>Wei-Bin Kou, Qingfeng Lin, Ming Tang, Sheng Xu, Rongguang Ye, Yang Leng, Shuai Wang, Guofa Li, Zhenyu Chen, Guangxu Zhu, Yik-Chung Wu</creator>
  </item>
  <item>
   <title>Language Guided Skill Discovery</title>
   <link>https://arxiv.org/abs/2406.06615</link>
   <description>Skill discovery methods enable agents to learn diverse emergent behaviors without explicit rewards. To make learned skills useful for unknown downstream tasks, obtaining a semantically diverse repertoire of skills is essential. While some approaches introduce a discriminator to distinguish skills and others aim to increase state coverage, no existing work directly addresses the &quot;semantic diversity&quot; of skills. We hypothesize that leveraging the semantic knowledge of large language models (LLMs) can lead us to improve semantic diversity of resulting behaviors. In this sense, we introduce Language Guided Skill Discovery (LGSD), a skill discovery framework that aims to directly maximize the semantic diversity between skills. LGSD takes user prompts as input and outputs a set of semantically distinctive skills. The prompts serve as a means to constrain the search space into a semantically desired subspace, and the generated LLM outputs guide the agent to visit semantically diverse states within the subspace. We demonstrate that LGSD enables legged robots to visit different user-intended areas on a plane by simply changing the prompt. Furthermore, we show that language guidance aids in discovering more diverse skills compared to five existing skill discovery methods in robot-arm manipulation environments. Lastly, LGSD provides a simple way of utilizing learned skills via natural language.</description>
   <guid>oai:arXiv.org:2406.06615v2</guid>
   <category>cs.CL</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <category>cs.RO</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Seungeun Rho, Laura Smith, Tianyu Li, Sergey Levine, Xue Bin Peng, Sehoon Ha</creator>
  </item>
  <item>
   <title>FLStore: Efficient Federated Learning Storage for non-training workloads</title>
   <link>https://arxiv.org/abs/2503.00323</link>
   <description>Federated Learning (FL) is an approach for privacy-preserving Machine Learning (ML), enabling model training across multiple clients without centralized data collection. With an aggregator server coordinating training, aggregating model updates, and storing metadata across rounds. In addition to training, a substantial part of FL systems are the non-training workloads such as scheduling, personalization, clustering, debugging, and incentivization. Most existing systems rely on the aggregator to handle non-training workloads and use cloud services for data storage. This results in high latency and increased costs as non-training workloads rely on large volumes of metadata, including weight parameters from client updates, hyperparameters, and aggregated updates across rounds, making the situation even worse. We propose FLStore, a serverless framework for efficient FL non-training workloads and storage. FLStore unifies the data and compute planes on a serverless cache, enabling locality-aware execution via tailored caching policies to reduce latency and costs. Per our evaluations, compared to cloud object store based aggregator server FLStore reduces per request average latency by 71% and costs by 92.45%, with peak improvements of 99.7% and 98.8%, respectively. Compared to an in-memory cloud cache based aggregator server, FLStore reduces average latency by 64.6% and costs by 98.83%, with peak improvements of 98.8% and 99.6%, respectively. FLStore integrates seamlessly with existing FL frameworks with minimal modifications, while also being fault-tolerant and highly scalable.</description>
   <guid>oai:arXiv.org:2503.00323v1</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Ahmad Faraz Khan, Samuel Fountain, Ahmed M. Abdelmoniem, Ali R. Butt, Ali Anwar</creator>
  </item>
  <item>
   <title>Conditioning on Local Statistics for Scalable Heterogeneous Federated Learning</title>
   <link>https://arxiv.org/abs/2503.00378</link>
   <description>Federated learning is a distributed machine learning approach where multiple clients collaboratively train a model without sharing their local data, which contributes to preserving privacy. A challenge in federated learning is managing heterogeneous data distributions across clients, which can hinder model convergence and performance due to the need for the global model to generalize well across diverse local datasets. We propose to use local characteristic statistics, by which we mean some statistical properties calculated independently by each client using only their local training dataset. These statistics, such as means, covariances, and higher moments, are used to capture the characteristics of the local data distribution. They are not shared with other clients or a central node. During training, these local statistics help the model learn how to condition on the local data distribution, and during inference, they guide the client's predictions. Our experiments show that this approach allows for efficient handling of heterogeneous data across the federation, has favorable scaling compared to approaches that directly try to identify peer nodes that share distribution characteristics, and maintains privacy as no additional information needs to be communicated.</description>
   <guid>oai:arXiv.org:2503.00378v1</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <category>cs.CR</category>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Rickard Br\&quot;annvall</creator>
  </item>
  <item>
   <title>Progressive Sparse Attention: Algorithm and System Co-design for Efficient Attention in LLM Serving</title>
   <link>https://arxiv.org/abs/2503.00392</link>
   <description>Processing long contexts has become a critical capability for modern large language models (LLMs). However, serving long-context LLMs comes with significant inference costs due to the high memory overhead of the key-value (KV) cache. Existing work leverages dynamic sparse attention algorithms (DSAes) to mitigate the KV cache overhead, but these algorithms rely on top-$k$ KV cache selection, which results in a trade-off between accuracy and efficiency. A larger $k$ improves accuracy but decreases efficiency, while a smaller $k$ boosts efficiency but compromises accuracy. To overcome this trade-off, this paper presents PSA, a $\underline{P}$rogressive $\underline{S}$parse $\underline{A}$ttention mechanism that integrates algorithmic innovations with system co-design to achieve both high inference accuracy and improved efficiency in LLM serving. The PSA algorithm adaptively adjusts the KV cache budget of different tokens and layers according to their real attention weight distributions, rather than relying on a fixed budget $k$. This enables high accuracy while minimizing KV cache usage. To further enhance execution efficiency, we introduce a pipelined iteration scheme that reduces CPU-GPU interleaving and synchronization overhead during PSA computation. Additionally, we implement unified GPU memory management that optimizes PSA's memory utilization by accounting for uneven memory requirements across different model layers. Extensive experimental results demonstrate that PSA reduces KV cache usage for attention computation by up to 2.4$\times$ and 8.8$\times$, and increases end-to-end serving throughput by up to 1.4$\times$ and 2.0$\times$, compared to state-of-the-art DSAes and systems without sparse attention, respectively.</description>
   <guid>oai:arXiv.org:2503.00392v1</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</rights>
   <creator>Qihui Zhou, Peiqi Yin, Pengfei Zuo, James Cheng</creator>
  </item>
  <item>
   <title>Asynchronous Personalized Federated Learning through Global Memorization</title>
   <link>https://arxiv.org/abs/2503.00407</link>
   <description>The proliferation of Internet of Things devices and advances in communication technology have unleashed an explosion of personal data, amplifying privacy concerns amid stringent regulations like GDPR and CCPA. Federated Learning offers a privacy preserving solution by enabling collaborative model training across decentralized devices without centralizing sensitive data. However, statistical heterogeneity from non-independent and identically distributed datasets and system heterogeneity due to client dropouts particularly those with monopolistic classes severely degrade the global model's performance. To address these challenges, we propose the Asynchronous Personalized Federated Learning framework, which empowers clients to develop personalized models using a server side semantic generator. This generator, trained via data free knowledge transfer under global model supervision, enhances client data diversity by producing both seen and unseen samples, the latter enabled by Zero-Shot Learning to mitigate dropout-induced data loss. To counter the risks of synthetic data impairing training, we introduce a decoupled model interpolation method, ensuring robust personalization. Extensive experiments demonstrate that AP FL significantly outperforms state of the art FL methods in tackling non-IID distributions and client dropouts, achieving superior accuracy and resilience across diverse real-world scenarios.</description>
   <guid>oai:arXiv.org:2503.00407v1</guid>
   <category>cs.LG</category>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Fan Wan, Yuchen Li, Xueqi Qiu, Rui Sun, Leyuan Zhang, Xingyu Miao, Tianyu Zhang, Haoran Duan, Yang Long</creator>
  </item>
  <item>
   <title>Communication-Efficient Device Scheduling for Federated Learning Using Lyapunov Optimization</title>
   <link>https://arxiv.org/abs/2503.00569</link>
   <description>Federated learning (FL) is a useful tool that enables the training of machine learning models over distributed data without having to collect data centrally. When deploying FL in constrained wireless environments, however, intermittent connectivity of devices, heterogeneous connection quality, and non-i.i.d. data can severely slow convergence. In this paper, we consider FL with arbitrary device participation probabilities for each round and show that by weighing each device's update by the reciprocal of their per-round participation probability, we can guarantee convergence to a stationary point. Our bound applies to non-convex loss functions and non-i.i.d. datasets and recovers state-of-the-art convergence rates for both full and uniform partial participation, including linear speedup, with only a single-sided learning rate. Then, using the derived convergence bound, we develop a new online client selection and power allocation algorithm that utilizes the Lyapunov drift-plus-penalty framework to opportunistically minimize a function of the convergence bound and the average communication time under a transmit power constraint. We use optimization over manifold techniques to obtain a solution to the minimization problem. Thanks to the Lyapunov framework, one key feature of the algorithm is that knowledge of the channel distribution is not required and only the instantaneous channel state information needs to be known. Using the CIFAR-10 dataset with varying levels of data heterogeneity, we show through simulations that the communication time can be significantly decreased using our algorithm compared to uniformly random participation, especially for heterogeneous channel conditions.</description>
   <guid>oai:arXiv.org:2503.00569v1</guid>
   <category>cs.LG</category>
   <category>cs.DC</category>
   <category>stat.ML</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Jake B. Perazzone, Shiqiang Wang, Mingyue Ji, Kevin Chan</creator>
  </item>
  <item>
   <title>Efficiently Editing Mixture-of-Experts Models with Compressed Experts</title>
   <link>https://arxiv.org/abs/2503.00634</link>
   <description>Mixture-of-Experts (MoE) models have become a key approach for scaling large language models efficiently by activating only a subset of experts during training and inference. Typically, the number of activated experts presents a trade-off: fewer experts reduce computational costs, while more experts improve performance. Recent studies reveal that not all activated experts contribute equally to model performance, with some providing minimal utility, particularly when finetuning pretrained MoE models for specialized downstream tasks. The co-existence of significant and redundant parameters in experts provides us an opportunity to reduce the number of activated experts while maintaining model performance. In this work, we propose the concept of compressed experts, lightweight modules that serve as compact representations of full experts. Our approach preserves the most important experts while replacing other auxiliary activated experts with compressed experts. The reduction of active parameters significantly lowers inference costs while achieving comparable performance. Extensive experiments on models including Phi-MoE and OLMoE demonstrate that compressed experts recover over 90% of full expert performance across various tasks while reducing more than 30% active parameters and saving 20% in inference costs. This approach enables efficient deployment of MoE models in resource-constrained settings and facilitates scaling to larger models with manageable overhead. Our code is available at https://github.com/yifei-he/Compressed-Experts.</description>
   <guid>oai:arXiv.org:2503.00634v1</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Yifei He, Yang Liu, Chen Liang, Hany Hassan Awadalla</creator>
  </item>
  <item>
   <title>MAB-Based Channel Scheduling for Asynchronous Federated Learning in Non-Stationary Environments</title>
   <link>https://arxiv.org/abs/2503.01324</link>
   <description>Federated learning enables distributed model training across clients under central coordination without raw data exchange. However, in wireless implementations, frequent parameter updates between the server and clients create significant communication overhead. While existing research assumes known channel state information (CSI) or stationary distributions, practical wireless channels exhibit non-stationary characteristics due to channel fading, user mobility, and hostile attacks. The unavailability of CSI and time-varying statistics can cause unpredictable transmission failures, exacerbating client staleness and affecting model convergence. To address these challenges, we propose an asynchronous federated learning scheduling framework for non-stationary channel environments to reduce staleness while promoting fair and efficient communication and aggregation.We focus on two channel scenarios: extremely non-stationary and piecewise stationary. Age of Information (AoI) quantifies client staleness under non-stationary conditions. Through a rigorous convergence analysis, we explore how AoI and per-round client participation affect learning performance. The scheduling problem is modeled within a multi-armed bandit (MAB) framework, and we derive the theoretical lower bounds on AoI regret. Based on these findings, we develop scheduling strategies for both scenarios using the GLR-CUCB and M-exp3 algorithms, also deriving their respective upper bounds on AoI regret. To address imbalanced client updates, we introduce an adaptive allocation strategy that incorporates marginal utility and fairness. Simulations demonstrate that our algorithm reduces AoI regret growth, accelerates federated learning convergence, and promotes fairer aggregation.</description>
   <guid>oai:arXiv.org:2503.01324v1</guid>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Zhiyin Li, Yubo Yang, Tao Yang, Xiaofeng Wu, Ziyu Guo, Bo Hu</creator>
  </item>
  <item>
   <title>MoCFL: Mobile Cluster Federated Learning Framework for Highly Dynamic Network</title>
   <link>https://arxiv.org/abs/2503.01557</link>
   <description>Frequent fluctuations of client nodes in highly dynamic mobile clusters can lead to significant changes in feature space distribution and data drift, posing substantial challenges to the robustness of existing federated learning (FL) strategies. To address these issues, we proposed a mobile cluster federated learning framework (MoCFL). MoCFL enhances feature aggregation by introducing an affinity matrix that quantifies the similarity between local feature extractors from different clients, addressing dynamic data distribution changes caused by frequent client churn and topology changes. Additionally, MoCFL integrates historical and current feature information when training the global classifier, effectively mitigating the catastrophic forgetting problem frequently encountered in mobile scenarios. This synergistic combination ensures that MoCFL maintains high performance and stability in dynamically changing mobile environments. Experimental results on the UNSW-NB15 dataset show that MoCFL excels in dynamic environments, demonstrating superior robustness and accuracy while maintaining reasonable training costs.</description>
   <guid>oai:arXiv.org:2503.01557v1</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Kai Fang, Jiangtao Deng, Chengzu Dong, Usman Naseem, Tongcun Liu, Hailin Feng, Wei Wang</creator>
  </item>
  <item>
   <title>Heterogeneity Matters even More in Distributed Learning: Study from Generalization Perspective</title>
   <link>https://arxiv.org/abs/2503.01598</link>
   <description>In this paper, we investigate the effect of data heterogeneity across clients on the performance of distributed learning systems, i.e., one-round Federated Learning, as measured by the associated generalization error. Specifically, \(K\) clients have each \(n\) training samples generated independently according to a possibly different data distribution and their individually chosen models are aggregated by a central server. We study the effect of the discrepancy between the clients' data distributions on the generalization error of the aggregated model. First, we establish in-expectation and tail upper bounds on the generalization error in terms of the distributions. In part, the bounds extend the popular Conditional Mutual Information (CMI) bound which was developed for the centralized learning setting, i.e., \(K=1\), to the distributed learning setting with arbitrary number of clients $K \geq 1$. Then, we use a connection with information theoretic rate-distortion theory to derive possibly tighter \textit{lossy} versions of these bounds. Next, we apply our lossy bounds to study the effect of data heterogeneity across clients on the generalization error for distributed classification problem in which each client uses Support Vector Machines (D-SVM). In this case, we establish explicit generalization error bounds which depend explicitly on the data heterogeneity degree. It is shown that the bound gets smaller as the degree of data heterogeneity across clients gets higher, thereby suggesting that D-SVM generalizes better when the dissimilarity between the clients' training samples is bigger. This finding, which goes beyond D-SVM, is validated experimentally through a number of experiments.</description>
   <guid>oai:arXiv.org:2503.01598v1</guid>
   <category>cs.LG</category>
   <category>cs.IT</category>
   <category>math.IT</category>
   <category>stat.ML</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Masoud Kavian, Milad Sefidgaran, Abdellatif Zaidi, Romain Chor</creator>
  </item>
  <item>
   <title>Using (Not so) Large Language Models for Generating Simulation Models in a Formal DSL -- A Study on Reaction Networks</title>
   <link>https://arxiv.org/abs/2503.01675</link>
   <description>Formal languages are an integral part of modeling and simulation. They allow the distillation of knowledge into concise simulation models amenable to automatic execution, interpretation, and analysis. However, the arguably most humanly accessible means of expressing models is through natural language, which is not easily interpretable by computers. Here, we evaluate how a Large Language Model (LLM) might be used for formalizing natural language into simulation models. Existing studies only explored using very large LLMs, like the commercial GPT models, without fine-tuning model weights. To close this gap, we show how an open-weights, 7B-parameter Mistral model can be fine-tuned to translate natural language descriptions to reaction network models in a domain-specific language, offering a self-hostable, compute-, and memory efficient alternative. To this end, we develop a synthetic data generator to serve as the basis for fine-tuning and evaluation. Our quantitative evaluation shows that our fine-tuned Mistral model can recover the ground truth simulation model in up to 84.5% of cases. In addition, our small-scale user study demonstrates the model's practical potential for one-time generation as well as interactive modeling in various domains. While promising, in its current form, the fine-tuned small LLM cannot catch up with large LLMs. We conclude that higher-quality training data are required, and expect future small and open-source LLMs to offer new opportunities.</description>
   <guid>oai:arXiv.org:2503.01675v1</guid>
   <category>cs.LG</category>
   <category>cs.CL</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Justin N. Kreikemeyer, Mi{\l}osz Jankowski, Pia Wilsdorf, Adelinde M. Uhrmacher</creator>
  </item>
  <item>
   <title>DILEMMA: Joint LLM Quantization and Distributed LLM Inference Over Edge Computing Systems</title>
   <link>https://arxiv.org/abs/2503.01704</link>
   <description>With a recent trend of using Large Language Models (LLMs) for different applications within smart cities, there is a need for pushing these models toward the edge of network while still preserving their performance. Edge Computing (EC) as a physically closer computing resource to the end users can help to reduce the communication delay for serving end users' tasks for LLM-dependent services. However, EC servers have limited capacity in terms of communication, computation, and storage capacity. This paper introduces DILEMMA, a novel framework addressing the challenges of deploying LLMs in EC systems by jointly optimizing layer placement and layer quantization in EC systems. DILEMMA formulates an Integer Linear Programming problem to minimize total inference delay while ensuring acceptable LLM performance levels, leveraging layer-wise quantization and knowledge distillation for LLM performance control. Experimental evaluations on OPT-350 model using the SQuAD dataset demonstrate that DILEMMA achieves a quantization ratio of up to 12.75% while preserving model loss, highlighting its effectiveness in resource-constrained environments.</description>
   <guid>oai:arXiv.org:2503.01704v1</guid>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/publicdomain/zero/1.0/</rights>
   <creator>Minoo Hosseinzadeh, Hana Khamfroush</creator>
  </item>
  <item>
   <title>GRAIN: Exact Graph Reconstruction from Gradients</title>
   <link>https://arxiv.org/abs/2503.01838</link>
   <description>Federated learning claims to enable collaborative model training among multiple clients with data privacy by transmitting gradient updates instead of the actual client data. However, recent studies have shown the client privacy is still at risk due to the, so called, gradient inversion attacks which can precisely reconstruct clients' text and image data from the shared gradient updates. While these attacks demonstrate severe privacy risks for certain domains and architectures, the vulnerability of other commonly-used data types, such as graph-structured data, remain under-explored. To bridge this gap, we present GRAIN, the first exact gradient inversion attack on graph data in the honest-but-curious setting that recovers both the structure of the graph and the associated node features. Concretely, we focus on Graph Convolutional Networks (GCN) and Graph Attention Networks (GAT) -- two of the most widely used frameworks for learning on graphs. Our method first utilizes the low-rank structure of GNN gradients to efficiently reconstruct and filter the client subgraphs which are then joined to complete the input graph. We evaluate our approach on molecular, citation, and social network datasets using our novel metric. We show that GRAIN reconstructs up to 80% of all graphs exactly, significantly outperforming the baseline, which achieves up to 20% correctly positioned nodes.</description>
   <guid>oai:arXiv.org:2503.01838v1</guid>
   <category>cs.LG</category>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by-sa/4.0/</rights>
   <creator>Maria Drencheva, Ivo Petrov, Maximilian Baader, Dimitar I. Dimitrov, Martin Vechev</creator>
  </item>
  <item>
   <title>Fed-KAN: Federated Learning with Kolmogorov-Arnold Networks for Traffic Prediction</title>
   <link>https://arxiv.org/abs/2503.00154</link>
   <description>Non-Terrestrial Networks (NTNs) are becoming a critical component of modern communication infrastructures, especially with the advent of Low Earth Orbit (LEO) satellite systems. Traditional centralized learning approaches face major challenges in such networks due to high latency, intermittent connectivity and limited bandwidth. Federated Learning (FL) is a promising alternative as it enables decentralized training while maintaining data privacy. However, existing FL models, such as Federated Learning with Multi-Layer Perceptrons (Fed-MLP), can struggle with high computational complexity and poor adaptability to dynamic NTN environments. This paper provides a detailed analysis for Federated Learning with Kolmogorov-Arnold Networks (Fed-KAN), its implementation and performance improvements over traditional FL models in NTN environments for traffic forecasting. The proposed Fed-KAN is a novel approach that utilises the functional approximation capabilities of KANs in a FL framework. We evaluate Fed-KAN compared to Fed-MLP on a traffic dataset of real satellite operator and show a significant reduction in training and test loss. Our results show that Fed-KAN can achieve a 77.39% reduction in average test loss compared to Fed-MLP, highlighting its improved performance and better generalization ability. At the end of the paper, we also discuss some potential applications of Fed-KAN within O-RAN and Fed-KAN usage for split functionalities in NTN architecture.</description>
   <guid>oai:arXiv.org:2503.00154v1</guid>
   <category>cs.NI</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Engin Zeydan, Cristian J. Vaca-Rubio, Luis Blanco, Roberto Pereira, Marius Caus, Kapal Dev</creator>
  </item>
  <item>
   <title>Safety Tax: Safety Alignment Makes Your Large Reasoning Models Less Reasonable</title>
   <link>https://arxiv.org/abs/2503.00555</link>
   <description>Safety alignment is an important procedure before the official deployment of a Large Language Model (LLM). While safety alignment has been extensively studied for LLM, there is still a large research gap for Large Reasoning Models (LRMs) that equip with improved reasoning capability. We in this paper systematically examine a simplified pipeline for producing safety aligned LRMs. With our evaluation of various LRMs, we deliver two main findings: i) Safety alignment can be done upon the LRM to restore its safety capability. ii) Safety alignment leads to a degradation of the reasoning capability of LRMs. The two findings show that there exists a trade-off between reasoning and safety capability with the sequential LRM production pipeline. The discovered trade-off, which we name Safety Tax, should shed light on future endeavors of safety research on LRMs. As a by-product, we curate a dataset called DirectRefusal, which might serve as an alternative dataset for safety alignment. Our source code is available at https://github.com/git-disl/Safety-Tax.</description>
   <guid>oai:arXiv.org:2503.00555v1</guid>
   <category>cs.CR</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim Furkan Tekin, Zachary Yahn, Yichang Xu, Ling Liu</creator>
  </item>
  <item>
   <title>PinLanding: Content-First Keyword Landing Page Generation via Multi-Modal AI for Web-Scale Discovery</title>
   <link>https://arxiv.org/abs/2503.00619</link>
   <description>Online platforms like Pinterest hosting vast content collections traditionally rely on manual curation or user-generated search logs to create keyword landing pages (KLPs) -- topic-centered collection pages that serve as entry points for content discovery. While manual curation ensures quality, it doesn't scale to millions of collections, and search log approaches result in limited topic coverage and imprecise content matching. In this paper, we present PinLanding, a novel content-first architecture that transforms the way platforms create topical collections. Instead of deriving topics from user behavior, our system employs a multi-stage pipeline combining vision-language model (VLM) for attribute extraction, large language model (LLM) for topic generation, and a CLIP-based dual-encoder architecture for precise content matching. Our model achieves 99.7% Recall@10 on Fashion200K benchmark, demonstrating strong attribute understanding capabilities. In production deployment for search engine optimization with 4.2 million shopping landing pages, the system achieves a 4X increase in topic coverage and 14.29% improvement in collection attribute precision over the traditional search log-based approach via human evaluation. The architecture can be generalized beyond search traffic to power various user experiences, including content discovery and recommendations, providing a scalable solution to transform unstructured content into curated topical collections across any content domain.</description>
   <guid>oai:arXiv.org:2503.00619v1</guid>
   <category>cs.IR</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Faye Zhang, Jasmine Wan, Qianyu Cheng, Jinfeng Rao</creator>
  </item>
  <item>
   <title>Same Question, Different Words: A Latent Adversarial Framework for Prompt Robustness</title>
   <link>https://arxiv.org/abs/2503.01345</link>
   <description>Insensitivity to semantically-preserving variations of prompts (paraphrases) is crucial for reliable behavior and real-world deployment of large language models. However, language models exhibit significant performance degradation when faced with semantically equivalent but differently phrased prompts, and existing solutions either depend on trial-and-error prompt engineering or require computationally expensive inference-time algorithms. In this study, built on the key insight that worst-case prompts exhibit a drift in embedding space, we present Latent Adversarial Paraphrasing (LAP), a dual-loop adversarial framework: the inner loop trains a learnable perturbation to serve as a &quot;latent continuous paraphrase&quot; while preserving semantics through Lagrangian regulation, and the outer loop optimizes the language model parameters on these perturbations. We conduct extensive experiments to demonstrate the effectiveness of LAP across multiple LLM architectures on the RobustAlpaca benchmark with a 0.5%-4% absolution improvement on worst-case win-rate compared with vanilla supervised fine-tuning.</description>
   <guid>oai:arXiv.org:2503.01345v1</guid>
   <category>cs.CL</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Tingchen Fu, Fazl Barez</creator>
  </item>
  <item>
   <title>AutoAdvExBench: Benchmarking autonomous exploitation of adversarial example defenses</title>
   <link>https://arxiv.org/abs/2503.01811</link>
   <description>We introduce AutoAdvExBench, a benchmark to evaluate if large language models (LLMs) can autonomously exploit defenses to adversarial examples. Unlike existing security benchmarks that often serve as proxies for real-world tasks, bench directly measures LLMs' success on tasks regularly performed by machine learning security experts. This approach offers a significant advantage: if a LLM could solve the challenges presented in bench, it would immediately present practical utility for adversarial machine learning researchers. We then design a strong agent that is capable of breaking 75% of CTF-like (&quot;homework exercise&quot;) adversarial example defenses. However, we show that this agent is only able to succeed on 13% of the real-world defenses in our benchmark, indicating the large gap between difficulty in attacking &quot;real&quot; code, and CTF-like code. In contrast, a stronger LLM that can attack 21% of real defenses only succeeds on 54% of CTF-like defenses. We make this benchmark available at https://github.com/ethz-spylab/AutoAdvExBench.</description>
   <guid>oai:arXiv.org:2503.01811v1</guid>
   <category>cs.CR</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Nicholas Carlini, Javier Rando, Edoardo Debenedetti, Milad Nasr, Florian Tram\`er</creator>
  </item>
  <item>
   <title>Rethinking Channel Dimensions to Isolate Outliers for Low-bit Weight Quantization of Large Language Models</title>
   <link>https://arxiv.org/abs/2309.15531</link>
   <description>Large Language Models (LLMs) have recently demonstrated remarkable success across various tasks. However, efficiently serving LLMs has been a challenge due to the large memory bottleneck, specifically in small batch inference settings (e.g. mobile devices). Weight-only quantization can be a promising approach, but sub-4 bit quantization remains a challenge due to large-magnitude activation outliers. To mitigate the undesirable outlier effect, we first propose per-IC quantization, a simple yet effective method that creates quantization groups within each input channel (IC) rather than the conventional per-output-channel (per-OC). Our method is motivated by the observation that activation outliers affect the input dimension of the weight matrix, so similarly grouping the weights in the IC direction can isolate outliers within a group. We also find that activation outliers do not dictate quantization difficulty, and inherent weight sensitivities also exist. With per-IC quantization as a new outlier-friendly scheme, we propose Adaptive Dimensions (AdaDim), a versatile quantization framework that can adapt to various weight sensitivity patterns. We demonstrate the effectiveness of AdaDim by augmenting prior methods such as Round-To-Nearest and GPTQ, showing significant improvements across various language modeling benchmarks for both base (up to +4.7% on MMLU) and instruction-tuned (up to +10% on HumanEval) LLMs. Code is available at https://github.com/johnheo/adadim-llm</description>
   <guid>oai:arXiv.org:2309.15531v3</guid>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Jung Hwan Heo, Jeonghoon Kim, Beomseok Kwon, Byeongwook Kim, Se Jung Kwon, Dongsoo Lee</creator>
  </item>
  <item>
   <title>Enhancing Clustered Federated Learning: Integration of Strategies and Improved Methodologies</title>
   <link>https://arxiv.org/abs/2310.05397</link>
   <description>Federated Learning (FL) is an evolving distributed machine learning approach that safeguards client privacy by keeping data on edge devices. However, the variation in data among clients poses challenges in training models that excel across all local distributions. Recent studies suggest clustering as a solution to address client heterogeneity in FL by grouping clients with distribution shifts into distinct clusters. Nonetheless, the diverse learning frameworks used in current clustered FL methods create difficulties in integrating these methods, leveraging their advantages, and making further enhancements. To this end, this paper conducts a thorough examination of existing clustered FL methods and introduces a four-tier framework, named HCFL, to encompass and extend the existing approaches. Utilizing the HCFL, we identify persistent challenges associated with current clustering methods in each tier and propose an enhanced clustering method called HCFL$^{+}$ to overcome these challenges. Through extensive numerical evaluations, we demonstrate the effectiveness of our clustering framework and the enhanced components. Our code is available at https://github.com/LINs-lab/HCFL.</description>
   <guid>oai:arXiv.org:2310.05397v2</guid>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Yongxin Guo, Xiaoying Tang, Tao Lin</creator>
  </item>
  <item>
   <title>Randomized Exploration in Cooperative Multi-Agent Reinforcement Learning</title>
   <link>https://arxiv.org/abs/2404.10728</link>
   <description>We present the first study on provably efficient randomized exploration in cooperative multi-agent reinforcement learning (MARL). We propose a unified algorithm framework for randomized exploration in parallel Markov Decision Processes (MDPs), and two Thompson Sampling (TS)-type algorithms, CoopTS-PHE and CoopTS-LMC, incorporating the perturbed-history exploration (PHE) strategy and the Langevin Monte Carlo exploration (LMC) strategy, respectively, which are flexible in design and easy to implement in practice. For a special class of parallel MDPs where the transition is (approximately) linear, we theoretically prove that both CoopTS-PHE and CoopTS-LMC achieve a $\widetilde{\mathcal{O}}(d^{3/2}H^2\sqrt{MK})$ regret bound with communication complexity $\widetilde{\mathcal{O}}(dHM^2)$, where $d$ is the feature dimension, $H$ is the horizon length, $M$ is the number of agents, and $K$ is the number of episodes. This is the first theoretical result for randomized exploration in cooperative MARL. We evaluate our proposed method on multiple parallel RL environments, including a deep exploration problem (i.e., $N$-chain), a video game, and a real-world problem in energy systems. Our experimental results support that our framework can achieve better performance, even under conditions of misspecified transition models. Additionally, we establish a connection between our unified framework and the practical application of federated learning.</description>
   <guid>oai:arXiv.org:2404.10728v2</guid>
   <category>cs.LG</category>
   <category>stat.ML</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Hao-Lun Hsu, Weixin Wang, Miroslav Pajic, Pan Xu</creator>
  </item>
  <item>
   <title>Where is the Testbed for my Federated Learning Research?</title>
   <link>https://arxiv.org/abs/2407.14154</link>
   <description>Progressing beyond centralized AI is of paramount importance, yet, distributed AI solutions, in particular various federated learning (FL) algorithms, are often not comprehensively assessed, which prevents the research community from identifying the most promising approaches and practitioners from being convinced that a certain solution is deployment-ready. The largest hurdle towards FL algorithm evaluation is the difficulty of conducting real-world experiments over a variety of FL client devices and different platforms, with different datasets and data distribution, all while assessing various dimensions of algorithm performance, such as inference accuracy, energy consumption, and time to convergence, to name a few. In this paper, we present CoLExT, a real-world testbed for FL research. CoLExT is designed to streamline experimentation with custom FL algorithms in a rich testbed configuration space, with a large number of heterogeneous edge devices, ranging from single-board computers to smartphones, and provides real-time collection and visualization of a variety of metrics through automatic instrumentation. According to our evaluation, porting FL algorithms to CoLExT requires minimal involvement from the developer, and the instrumentation introduces minimal resource usage overhead. Furthermore, through an initial investigation involving popular FL algorithms running on CoLExT, we reveal previously unknown trade-offs, inefficiencies, and programming bugs.</description>
   <guid>oai:arXiv.org:2407.14154v2</guid>
   <category>cs.LG</category>
   <category>cs.DC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Janez Bo\v{z}i\v{c}, Am\^andio R. Faustino, Boris Radovi\v{c}, Marco Canini, Veljko Pejovi\'c</creator>
  </item>
  <item>
   <title>FedBiP: Heterogeneous One-Shot Federated Learning with Personalized Latent Diffusion Models</title>
   <link>https://arxiv.org/abs/2410.04810</link>
   <description>One-Shot Federated Learning (OSFL), a special decentralized machine learning paradigm, has recently gained significant attention. OSFL requires only a single round of client data or model upload, which reduces communication costs and mitigates privacy threats compared to traditional FL. Despite these promising prospects, existing methods face challenges due to client data heterogeneity and limited data quantity when applied to real-world OSFL systems. Recently, Latent Diffusion Models (LDM) have shown remarkable advancements in synthesizing high-quality images through pretraining on large-scale datasets, thereby presenting a potential solution to overcome these issues. However, directly applying pretrained LDM to heterogeneous OSFL results in significant distribution shifts in synthetic data, leading to performance degradation in classification models trained on such data. This issue is particularly pronounced in rare domains, such as medical imaging, which are underrepresented in LDM's pretraining data. To address this challenge, we propose Federated Bi-Level Personalization (FedBiP), which personalizes the pretrained LDM at both instance-level and concept-level. Hereby, FedBiP synthesizes images following the client's local data distribution without compromising the privacy regulations. FedBiP is also the first approach to simultaneously address feature space heterogeneity and client data scarcity in OSFL. Our method is validated through extensive experiments on three OSFL benchmarks with feature space heterogeneity, as well as on challenging medical and satellite image datasets with label heterogeneity. The results demonstrate the effectiveness of FedBiP, which substantially outperforms other OSFL methods.</description>
   <guid>oai:arXiv.org:2410.04810v2</guid>
   <category>cs.LG</category>
   <category>cs.CV</category>
   <category>cs.DC</category>
   <category>cs.MM</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Haokun Chen, Hang Li, Yao Zhang, Jinhe Bi, Gengyuan Zhang, Yueqi Zhang, Philip Torr, Jindong Gu, Denis Krompass, Volker Tresp</creator>
  </item>
  <item>
   <title>Federated Learning in Practice: Reflections and Projections</title>
   <link>https://arxiv.org/abs/2410.08892</link>
   <description>Federated Learning (FL) is a machine learning technique that enables multiple entities to collaboratively learn a shared model without exchanging their local data. Over the past decade, FL systems have achieved substantial progress, scaling to millions of devices across various learning domains while offering meaningful differential privacy (DP) guarantees. Production systems from organizations like Google, Apple, and Meta demonstrate the real-world applicability of FL. However, key challenges remain, including verifying server-side DP guarantees and coordinating training across heterogeneous devices, limiting broader adoption. Additionally, emerging trends such as large (multi-modal) models and blurred lines between training, inference, and personalization challenge traditional FL frameworks. In response, we propose a redefined FL framework that prioritizes privacy principles rather than rigid definitions. We also chart a path forward by leveraging trusted execution environments and open-source ecosystems to address these challenges and facilitate future advancements in FL.</description>
   <guid>oai:arXiv.org:2410.08892v2</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <category>cs.CR</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Katharine Daly, Hubert Eichner, Peter Kairouz, H. Brendan McMahan, Daniel Ramage, Zheng Xu</creator>
  </item>
  <item>
   <title>RAIFLE: Reconstruction Attacks on Interaction-based Federated Learning with Adversarial Data Manipulation</title>
   <link>https://arxiv.org/abs/2310.19163</link>
   <description>Federated learning has emerged as a promising privacy-preserving solution for machine learning domains that rely on user interactions, particularly recommender systems and online learning to rank. While there has been substantial research on the privacy of traditional federated learning, little attention has been paid to the privacy properties of these interaction-based settings. In this work, we show that users face an elevated risk of having their private interactions reconstructed by the central server when the server can control the training features of the items that users interact with. We introduce RAIFLE, a novel optimization-based attack framework where the server actively manipulates the features of the items presented to users to increase the success rate of reconstruction. Our experiments with federated recommendation and online learning-to-rank scenarios demonstrate that RAIFLE is significantly more powerful than existing reconstruction attacks like gradient inversion, achieving high performance consistently in most settings. We discuss the pros and cons of several possible countermeasures to defend against RAIFLE in the context of interaction-based federated learning. Our code is open-sourced at https://github.com/dzungvpham/raifle.</description>
   <guid>oai:arXiv.org:2310.19163v3</guid>
   <category>cs.CR</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</rights>
   <creator>Dzung Pham, Shreyas Kulkarni, Amir Houmansadr</creator>
  </item>
  <item>
   <title>Confidential Federated Computations</title>
   <link>https://arxiv.org/abs/2404.10764</link>
   <description>Federated Learning and Analytics (FLA) have seen widespread adoption by technology platforms for processing sensitive on-device data. However, basic FLA systems have privacy limitations: they do not necessarily require anonymization mechanisms like differential privacy (DP), and provide limited protections against a potentially malicious service provider. Adding DP to a basic FLA system currently requires either adding excessive noise to each device's updates, or assuming an honest service provider that correctly implements the mechanism and only uses the privatized outputs. Secure multiparty computation (SMPC) -based oblivious aggregations can limit the service provider's access to individual user updates and improve DP tradeoffs, but the tradeoffs are still suboptimal, and they suffer from scalability challenges and susceptibility to Sybil attacks. This paper introduces a novel system architecture that leverages trusted execution environments (TEEs) and open-sourcing to both ensure confidentiality of server-side computations and provide externally verifiable privacy properties, bolstering the robustness and trustworthiness of private federated computations.</description>
   <guid>oai:arXiv.org:2404.10764v2</guid>
   <category>cs.CR</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Hubert Eichner, Daniel Ramage, Kallista Bonawitz, Dzmitry Huba, Tiziano Santoro, Brett McLarnon, Timon Van Overveldt, Nova Fallen, Peter Kairouz, Albert Cheu, Katharine Daly, Adria Gascon, Marco Gruteser, Brendan McMahan</creator>
  </item>
  <item>
   <title>Language Guided Skill Discovery</title>
   <link>https://arxiv.org/abs/2406.06615</link>
   <description>Skill discovery methods enable agents to learn diverse emergent behaviors without explicit rewards. To make learned skills useful for unknown downstream tasks, obtaining a semantically diverse repertoire of skills is essential. While some approaches introduce a discriminator to distinguish skills and others aim to increase state coverage, no existing work directly addresses the &quot;semantic diversity&quot; of skills. We hypothesize that leveraging the semantic knowledge of large language models (LLMs) can lead us to improve semantic diversity of resulting behaviors. In this sense, we introduce Language Guided Skill Discovery (LGSD), a skill discovery framework that aims to directly maximize the semantic diversity between skills. LGSD takes user prompts as input and outputs a set of semantically distinctive skills. The prompts serve as a means to constrain the search space into a semantically desired subspace, and the generated LLM outputs guide the agent to visit semantically diverse states within the subspace. We demonstrate that LGSD enables legged robots to visit different user-intended areas on a plane by simply changing the prompt. Furthermore, we show that language guidance aids in discovering more diverse skills compared to five existing skill discovery methods in robot-arm manipulation environments. Lastly, LGSD provides a simple way of utilizing learned skills via natural language.</description>
   <guid>oai:arXiv.org:2406.06615v2</guid>
   <category>cs.CL</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <category>cs.RO</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Seungeun Rho, Laura Smith, Tianyu Li, Sergey Levine, Xue Bin Peng, Sehoon Ha</creator>
  </item>
  <item>
   <title>Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models</title>
   <link>https://arxiv.org/abs/2501.14406</link>
   <description>Pre-trained Language Models (PLMs) have demonstrated their superiority and versatility in modern Natural Language Processing (NLP), effectively adapting to various downstream tasks through further fine-tuning. Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution to address privacy and efficiency challenges in distributed training for PLMs on resource-constrained local devices. However, our measurements reveal two key limitations of FedPEFT: heterogeneous data across devices leads to significant performance degradation, and a fixed parameter configuration results in communication inefficiency. To overcome these limitations, we propose FedARA, a novel Adaptive Rank Allocation framework for federated parameter-efficient fine-tuning of language models. Specifically, FedARA employs truncated Singular Value Decomposition (SVD) adaptation to enhance similar feature representation across clients, significantly mitigating the adverse effects of data heterogeneity. Subsequently, it utilizes dynamic rank allocation to progressively identify critical ranks, effectively improving communication efficiency. Lastly, it leverages rank-based module pruning to automatically remove inactive modules, steadily reducing local computational cost and memory usage in each federated learning round. Extensive experiments show that FedARA consistently outperforms baselines by an average of 6.95% to 8.49% across various datasets and models under heterogeneous data while significantly improving communication efficiency by 2.40$ \times$. Moreover, experiments on various edge devices demonstrate substantial decreases in total training time and energy consumption by up to 48.90% and 46.95%, respectively.</description>
   <guid>oai:arXiv.org:2501.14406v2</guid>
   <category>cs.DC</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <category>cs.NI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Fei Wu, Jia Hu, Geyong Min, Shiqiang Wang</creator>
  </item>
  <item>
   <title>Analytic Personalized Federated Meta-Learning</title>
   <link>https://arxiv.org/abs/2502.06915</link>
   <description>Analytic Federated Learning (AFL) is an enhanced gradient-free federated learning (FL) paradigm designed to accelerate training by updating the global model in a single step with closed-form least-square (LS) solutions. However, the obtained global model suffers performance degradation across clients with heterogeneous data distribution. Meta-learning is a common approach to tackle this problem by delivering personalized local models for individual clients. Yet, integrating meta-learning with AFL presents significant challenges: First, conventional AFL frameworks cannot support deep neural network (DNN) training which can influence the fast adaption capability of meta-learning for complex FL tasks. Second, the existing meta-learning method requires gradient information, which is not involved in AFL. To overcome the first challenge, we propose an AFL framework, namely FedACnnL, in which a layer-wise DNN collaborative training method is designed by modeling the training of each layer as a distributed LS problem. For the second challenge, we further propose an analytic personalized federated meta-learning framework, namely pFedACnnL. It generates a personalized model for each client by analytically solving a local objective which bridges the gap between the global model and the individual data distribution. FedACnnL is theoretically proven to require significantly shorter training time than the conventional FL frameworks on DNN training while the reduction ratio is $83\%\sim99\%$ in the experiment. Meanwhile, pFedACnnL excels at test accuracy with the vanilla FedACnnL by $4\%\sim8\%$ and it achieves state-of-the-art (SOTA) model performance in most cases of convex and non-convex settings compared with previous SOTA frameworks.</description>
   <guid>oai:arXiv.org:2502.06915v2</guid>
   <category>cs.DC</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Shunxian Gu, Chaoqun You, Deke Guo, Zhihao Qu, Bangbang Ren, Zaipeng Xie, Lailong Luo</creator>
  </item>
  <item>
   <title>PinLanding: Content-First Keyword Landing Page Generation via Multi-Modal AI for Web-Scale Discovery</title>
   <link>https://arxiv.org/abs/2503.00619</link>
   <description>Online platforms like Pinterest hosting vast content collections traditionally rely on manual curation or user-generated search logs to create keyword landing pages (KLPs) -- topic-centered collection pages that serve as entry points for content discovery. While manual curation ensures quality, it doesn't scale to millions of collections, and search log approaches result in limited topic coverage and imprecise content matching. In this paper, we present PinLanding, a novel content-first architecture that transforms the way platforms create topical collections. Instead of deriving topics from user behavior, our system employs a multi-stage pipeline combining vision-language model (VLM) for attribute extraction, large language model (LLM) for topic generation, and a CLIP-based dual-encoder architecture for precise content matching. Our model achieves 99.7% Recall@10 on Fashion200K benchmark, demonstrating strong attribute understanding capabilities. In production deployment for search engine optimization with 4.2 million shopping landing pages, the system achieves a 4X increase in topic coverage and 14.29% improvement in collection attribute precision over the traditional search log-based approach via human evaluation. The architecture can be generalized beyond search traffic to power various user experiences, including content discovery and recommendations, providing a scalable solution to transform unstructured content into curated topical collections across any content domain.</description>
   <guid>oai:arXiv.org:2503.00619v1</guid>
   <category>cs.IR</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Faye Zhang, Jasmine Wan, Qianyu Cheng, Jinfeng Rao</creator>
  </item>
  <item>
   <title>Towards Efficient Educational Chatbots: Benchmarking RAG Frameworks</title>
   <link>https://arxiv.org/abs/2503.00781</link>
   <description>Large Language Models (LLMs) have proven immensely beneficial in education by capturing vast amounts of literature-based information, allowing them to generate context without relying on external sources. In this paper, we propose a generative AI-powered GATE question-answering framework (GATE stands for Graduate Aptitude Test in Engineering) that leverages LLMs to explain GATE solutions and support students in their exam preparation. We conducted extensive benchmarking to select the optimal embedding model and LLM, evaluating our framework based on criteria such as latency, faithfulness, and relevance, with additional validation through human evaluation. Our chatbot integrates state-of-the-art embedding models and LLMs to deliver accurate, context-aware responses. Through rigorous experimentation, we identified configurations that balance performance and computational efficiency, ensuring a reliable chatbot to serve students' needs. Additionally, we discuss the challenges faced in data processing and modeling and implemented solutions. Our work explores the application of Retrieval-Augmented Generation (RAG) for GATE Q/A explanation tasks, and our findings demonstrate significant improvements in retrieval accuracy and response quality. This research offers practical insights for developing effective AI-driven educational tools while highlighting areas for future enhancement in usability and scalability.</description>
   <guid>oai:arXiv.org:2503.00781v1</guid>
   <category>cs.IR</category>
   <category>cs.AI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Umar Ali Khan, Ekram Khan, Fiza Khan, Athar Ali Moinuddin</creator>
  </item>
  <item>
   <title>Towards An Efficient LLM Training Paradigm for CTR Prediction</title>
   <link>https://arxiv.org/abs/2503.01001</link>
   <description>Large Language Models (LLMs) have demonstrated tremendous potential as the next-generation ranking-based recommendation system. Many recent works have shown that LLMs can significantly outperform conventional click-through-rate (CTR) prediction approaches. Despite such promising results, the computational inefficiency inherent in the current training paradigm makes it particularly challenging to train LLMs for ranking-based recommendation tasks on large datasets. To train LLMs for CTR prediction, most existing studies adopt the prevalent ''sliding-window'' paradigm. Given a sequence of $m$ user interactions, a unique training prompt is constructed for each interaction by designating it as the prediction target along with its preceding $n$ interactions serving as context. In turn, the sliding-window paradigm results in an overall complexity of $O(mn^2)$ that scales linearly with the length of user interactions. Consequently, a direct adoption to train LLMs with such strategy can result in prohibitively high training costs as the length of interactions grows. To alleviate the computational inefficiency, we propose a novel training paradigm, namely Dynamic Target Isolation (DTI), that structurally parallelizes the training of $k$ (where $k &gt;&gt; 1$) target interactions. Furthermore, we identify two major bottlenecks - hidden-state leakage and positional bias overfitting - that limit DTI to only scale up to a small value of $k$ (e.g., 5) then propose a computationally light solution to effectively tackle each. Through extensive experiments on three widely adopted public CTR datasets, we empirically show that DTI reduces training time by an average of $\textbf{92%}$ (e.g., from $70.5$ hrs to $5.31$ hrs), without compromising CTR prediction performance.</description>
   <guid>oai:arXiv.org:2503.01001v1</guid>
   <category>cs.IR</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Allen Lin, Renqin Cai, Yun He, Hanchao Yu, Jing Qian, Rui Li, Qifan Wang, James Caverlee</creator>
  </item>
  <item>
   <title>Towards Multimodal Large-Language Models for Parent-Child Interaction: A Focus on Joint Attention</title>
   <link>https://arxiv.org/abs/2502.19877</link>
   <description>Joint attention is a critical component of early speech-language development and a key indicator of effective parent-child interaction. However, research on detecting and analysing joint attention remains limited, particularly for Multimodal Large Language Models (MLLMs). This study evaluates MLLMs' ability to comprehend joint attention by analysing 26 parent-child interaction videos annotated by two speech-language pathologists. These annotations identify strong and poor joint attention segments, serving as benchmarks for evaluating the models' interpretive capabilities. Our findings reveal that current MLLMs struggle to accurately interpret joint attention due to a lack of nuanced understanding of child-initiated eye contact, a crucial component of joint attention dynamics. This study highlights the importance of incorporating detailed eye contact to enhance MLLMs' multimodal reasoning. Addressing these gaps is essential for future research to advance the use of MLLMs in analysing and supporting parent-child interactions.</description>
   <guid>oai:arXiv.org:2502.19877v2</guid>
   <category>cs.HC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</rights>
   <creator>Weiyan Shi, Viet Hai Le, Kenny Tsu Wei Choo</creator>
  </item>
  <item>
   <title>User Intent to Use DeepSeek for Healthcare Purposes and their Trust in the Large Language Model: Multinational Survey Study</title>
   <link>https://arxiv.org/abs/2502.17487</link>
   <description>Large language models (LLMs) increasingly serve as interactive healthcare resources, yet user acceptance remains underexplored. This study examines how ease of use, perceived usefulness, trust, and risk perception interact to shape intentions to adopt DeepSeek, an emerging LLM-based platform, for healthcare purposes. A cross-sectional survey of 556 participants from India, the United Kingdom, and the United States was conducted to measure perceptions and usage patterns. Structural equation modeling assessed both direct and indirect effects, including potential quadratic relationships. Results revealed that trust plays a pivotal mediating role: ease of use exerts a significant indirect effect on usage intentions through trust, while perceived usefulness contributes to both trust development and direct adoption. By contrast, risk perception negatively affects usage intent, emphasizing the importance of robust data governance and transparency. Notably, significant non-linear paths were observed for ease of use and risk, indicating threshold or plateau effects. The measurement model demonstrated strong reliability and validity, supported by high composite reliabilities, average variance extracted, and discriminant validity measures. These findings extend technology acceptance and health informatics research by illuminating the multifaceted nature of user adoption in sensitive domains. Stakeholders should invest in trust-building strategies, user-centric design, and risk mitigation measures to encourage sustained and safe uptake of LLMs in healthcare. Future work can employ longitudinal designs or examine culture-specific variables to further clarify how user perceptions evolve over time and across different regulatory environments. Such insights are critical for harnessing AI to enhance outcomes.</description>
   <guid>oai:arXiv.org:2502.17487v2</guid>
   <category>cs.AI</category>
   <category>cs.CY</category>
   <category>cs.HC</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Avishek Choudhury, Yeganeh Shahsavar, Hamid Shamszare</creator>
  </item>
  <item>
   <title>Unmasking Digital Falsehoods: A Comparative Analysis of LLM-Based Misinformation Detection Strategies</title>
   <link>https://arxiv.org/abs/2503.00724</link>
   <description>The proliferation of misinformation on social media has raised significant societal concerns, necessitating robust detection mechanisms. Large Language Models such as GPT-4 and LLaMA2 have been envisioned as possible tools for detecting misinformation based on their advanced natural language understanding and reasoning capabilities. This paper conducts a comparison of LLM-based approaches to detecting misinformation between text-based, multimodal, and agentic approaches. We evaluate the effectiveness of fine-tuned models, zero-shot learning, and systematic fact-checking mechanisms in detecting misinformation across different topic domains like public health, politics, and finance. We also discuss scalability, generalizability, and explainability of the models and recognize key challenges such as hallucination, adversarial attacks on misinformation, and computational resources. Our findings point towards the importance of hybrid approaches that pair structured verification protocols with adaptive learning techniques to enhance detection accuracy and explainability. The paper closes by suggesting potential avenues of future work, including real-time tracking of misinformation, federated learning, and cross-platform detection models.</description>
   <guid>oai:arXiv.org:2503.00724v1</guid>
   <category>cs.CL</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Tianyi Huang, Jingyuan Yi, Peiyang Yu, Xiaochuan Xu</creator>
  </item>
  <item>
   <title>Babel: Open Multilingual Large Language Models Serving Over 90% of Global Speakers</title>
   <link>https://arxiv.org/abs/2503.00865</link>
   <description>Large language models (LLMs) have revolutionized natural language processing (NLP), yet open-source multilingual LLMs remain scarce, with existing models often limited in language coverage. Such models typically prioritize well-resourced languages, while widely spoken but under-resourced languages are often overlooked. To address this disparity, we introduce $\texttt{Babel}$, an open multilingual LLM that covers the top 25 languages by number of speakers, supports over 90% of the global population, and includes many languages neglected by other open multilingual LLMs. Unlike traditional continue pretraining approaches, Babel expands its parameter count through a layer extension technique that elevates Babel's performance ceiling. We introduce two variants: $\texttt{Babel-9B}$, designed for efficient inference and fine-tuning, and $\texttt{Babel-83B}$, which sets a new standard for open multilingual LLMs. Extensive evaluations on multilingual tasks demonstrate its superior performance compared to open LLMs of comparable size. In addition, using open-source supervised fine-tuning datasets, Babel achieves remarkable performance, with Babel-9B-Chat leading among 10B-sized LLMs and Babel-83B-Chat setting a new standard for multilingual tasks, reaching the same level of commercial models.</description>
   <guid>oai:arXiv.org:2503.00865v1</guid>
   <category>cs.CL</category>
   <category>cs.AI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Yiran Zhao, Chaoqun Liu, Yue Deng, Jiahao Ying, Mahani Aljunied, Zhaodonghui Li, Lidong Bing, Hou Pong Chan, Yu Rong, Deli Zhao, Wenxuan Zhang</creator>
  </item>
  <item>
   <title>WeightedKV: Attention Scores Weighted Key-Value Cache Merging for Large Language Models</title>
   <link>https://arxiv.org/abs/2503.01330</link>
   <description>Large Language Models (LLMs) use key-value (KV) cache to reduce redundant computation in autoregressive generation. However, the KV cache size increases linearly during generation, leading to excessive memory usage, especially for long texts. Most KV cache compression methods evict the unimportant KV pairs to maintain a fixed cache size, which leads to the permanent loss of tokens during generation. However, singular value decomposition shows that \textit{values} do not exhibit a strong low-rank property as \textit{keys} do, suggesting that information is distributed more evenly across \textit{values}, in contrast to its more redundant distribution within \textit{keys}. Therefore, methods that evict both \textit{keys} and \textit{values} risk losing crucial information and compromise context integrity, ultimately degrading the output quality. To address this problem, we propose WeightedKV, a novel, training-free approach that discards the \textit{keys} of less important tokens, while merging their \textit{values} into neighboring tokens via a convex combination weighted by their average attention scores. In this way, the retained \textit{keys} serve as anchors that guide the generation process, while the merged \textit{values} provide a rich contextual backdrop. We assess our method on four widely used language modeling datasets, demonstrating superior performance compared to all baseline methods, particularly with a lower budget ratio.</description>
   <guid>oai:arXiv.org:2503.01330v1</guid>
   <category>cs.CL</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Jian Yuan, Ziwei He, Haoli Bai, Jingwen Leng, Bo Jiang</creator>
  </item>
  <item>
   <title>Same Question, Different Words: A Latent Adversarial Framework for Prompt Robustness</title>
   <link>https://arxiv.org/abs/2503.01345</link>
   <description>Insensitivity to semantically-preserving variations of prompts (paraphrases) is crucial for reliable behavior and real-world deployment of large language models. However, language models exhibit significant performance degradation when faced with semantically equivalent but differently phrased prompts, and existing solutions either depend on trial-and-error prompt engineering or require computationally expensive inference-time algorithms. In this study, built on the key insight that worst-case prompts exhibit a drift in embedding space, we present Latent Adversarial Paraphrasing (LAP), a dual-loop adversarial framework: the inner loop trains a learnable perturbation to serve as a &quot;latent continuous paraphrase&quot; while preserving semantics through Lagrangian regulation, and the outer loop optimizes the language model parameters on these perturbations. We conduct extensive experiments to demonstrate the effectiveness of LAP across multiple LLM architectures on the RobustAlpaca benchmark with a 0.5%-4% absolution improvement on worst-case win-rate compared with vanilla supervised fine-tuning.</description>
   <guid>oai:arXiv.org:2503.01345v1</guid>
   <category>cs.CL</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Tingchen Fu, Fazl Barez</creator>
  </item>
  <item>
   <title>Using (Not so) Large Language Models for Generating Simulation Models in a Formal DSL -- A Study on Reaction Networks</title>
   <link>https://arxiv.org/abs/2503.01675</link>
   <description>Formal languages are an integral part of modeling and simulation. They allow the distillation of knowledge into concise simulation models amenable to automatic execution, interpretation, and analysis. However, the arguably most humanly accessible means of expressing models is through natural language, which is not easily interpretable by computers. Here, we evaluate how a Large Language Model (LLM) might be used for formalizing natural language into simulation models. Existing studies only explored using very large LLMs, like the commercial GPT models, without fine-tuning model weights. To close this gap, we show how an open-weights, 7B-parameter Mistral model can be fine-tuned to translate natural language descriptions to reaction network models in a domain-specific language, offering a self-hostable, compute-, and memory efficient alternative. To this end, we develop a synthetic data generator to serve as the basis for fine-tuning and evaluation. Our quantitative evaluation shows that our fine-tuned Mistral model can recover the ground truth simulation model in up to 84.5% of cases. In addition, our small-scale user study demonstrates the model's practical potential for one-time generation as well as interactive modeling in various domains. While promising, in its current form, the fine-tuned small LLM cannot catch up with large LLMs. We conclude that higher-quality training data are required, and expect future small and open-source LLMs to offer new opportunities.</description>
   <guid>oai:arXiv.org:2503.01675v1</guid>
   <category>cs.LG</category>
   <category>cs.CL</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Justin N. Kreikemeyer, Mi{\l}osz Jankowski, Pia Wilsdorf, Adelinde M. Uhrmacher</creator>
  </item>
  <item>
   <title>Language Guided Skill Discovery</title>
   <link>https://arxiv.org/abs/2406.06615</link>
   <description>Skill discovery methods enable agents to learn diverse emergent behaviors without explicit rewards. To make learned skills useful for unknown downstream tasks, obtaining a semantically diverse repertoire of skills is essential. While some approaches introduce a discriminator to distinguish skills and others aim to increase state coverage, no existing work directly addresses the &quot;semantic diversity&quot; of skills. We hypothesize that leveraging the semantic knowledge of large language models (LLMs) can lead us to improve semantic diversity of resulting behaviors. In this sense, we introduce Language Guided Skill Discovery (LGSD), a skill discovery framework that aims to directly maximize the semantic diversity between skills. LGSD takes user prompts as input and outputs a set of semantically distinctive skills. The prompts serve as a means to constrain the search space into a semantically desired subspace, and the generated LLM outputs guide the agent to visit semantically diverse states within the subspace. We demonstrate that LGSD enables legged robots to visit different user-intended areas on a plane by simply changing the prompt. Furthermore, we show that language guidance aids in discovering more diverse skills compared to five existing skill discovery methods in robot-arm manipulation environments. Lastly, LGSD provides a simple way of utilizing learned skills via natural language.</description>
   <guid>oai:arXiv.org:2406.06615v2</guid>
   <category>cs.CL</category>
   <category>cs.AI</category>
   <category>cs.LG</category>
   <category>cs.RO</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Seungeun Rho, Laura Smith, Tianyu Li, Sergey Levine, Xue Bin Peng, Sehoon Ha</creator>
  </item>
  <item>
   <title>Semantic Operators: A Declarative Model for Rich, AI-based Data Processing</title>
   <link>https://arxiv.org/abs/2407.11418</link>
   <description>The semantic capabilities of large language models (LLMs) have the potential to enable rich analytics and reasoning over vast knowledge corpora. Unfortunately, existing systems either empirically optimize expensive LLM-powered operations with no performance guarantees, or serve a limited set of row-wise LLM operations, providing limited robustness, expressiveness and usability. We introduce semantic operators, the first formalism for declarative and general-purpose AI-based transformations based on natural language specifications (e.g., filtering, sorting, joining or aggregating records using natural language criteria). Each operator opens a rich space for execution plans, similar to relational operators. Our model specifies the expected behavior of each operator with a high-quality gold algorithm, and we develop an optimization framework that reduces cost, while providing accuracy guarantees with respect to a gold algorithm. Using this approach, we propose several novel optimizations to accelerate semantic filtering, joining, group-by and top-k operations by up to $1,000\times$. We implement semantic operators in the LOTUS system and demonstrate LOTUS' effectiveness on real, bulk-semantic processing applications, including fact-checking, biomedical multi-label classification, search, and topic analysis. We show that the semantic operator model is expressive, capturing state-of-the-art AI pipelines in a few operator calls, and making it easy to express new pipelines that match or exceed quality of recent LLM-based analytic systems by up to $170\%$, while offering accuracy guarantees. Overall, LOTUS programs match or exceed the accuracy of state-of-the-art AI pipelines for each task while running up to $3.6\times$ faster than the highest-quality baselines. LOTUS is publicly available at https://github.com/lotus-data/lotus.</description>
   <guid>oai:arXiv.org:2407.11418v3</guid>
   <category>cs.DB</category>
   <category>cs.AI</category>
   <category>cs.CL</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Liana Patel, Siddharth Jha, Melissa Pan, Harshit Gupta, Parth Asawa, Carlos Guestrin, Matei Zaharia</creator>
  </item>
  <item>
   <title>Patient-Level Anatomy Meets Scanning-Level Physics: Personalized Federated Low-Dose CT Denoising Empowered by Large Language Model</title>
   <link>https://arxiv.org/abs/2503.00908</link>
   <description>Reducing radiation doses benefits patients, however, the resultant low-dose computed tomography (LDCT) images often suffer from clinically unacceptable noise and artifacts. While deep learning (DL) shows promise in LDCT reconstruction, it requires large-scale data collection from multiple clients, raising privacy concerns. Federated learning (FL) has been introduced to address these privacy concerns; however, current methods are typically tailored to specific scanning protocols, which limits their generalizability and makes them less effective for unseen protocols. To address these issues, we propose SCAN-PhysFed, a novel SCanning- and ANatomy-level personalized Physics-Driven Federated learning paradigm for LDCT reconstruction. Since the noise distribution in LDCT data is closely tied to scanning protocols and anatomical structures being scanned, we design a dual-level physics-informed way to address these challenges. Specifically, we incorporate physical and anatomical prompts into our physics-informed hypernetworks to capture scanning- and anatomy-specific information, enabling dual-level physics-driven personalization of imaging features. These prompts are derived from the scanning protocol and the radiology report generated by a medical large language model (MLLM), respectively. Subsequently, client-specific decoders project these dual-level personalized imaging features back into the image domain. Besides, to tackle the challenge of unseen data, we introduce a novel protocol vector-quantization strategy (PVQS), which ensures consistent performance across new clients by quantifying the unseen scanning code as one of the codes in the scanning codebook. Extensive experimental results demonstrate the superior performance of SCAN-PhysFed on public datasets.</description>
   <guid>oai:arXiv.org:2503.00908v1</guid>
   <category>eess.IV</category>
   <category>cs.CV</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Ziyuan Yang, Yingyu Chen, Zhiwen Wang, Hongming Shan, Yang Chen, Yi Zhang</creator>
  </item>
  <item>
   <title>StarVid: Enhancing Semantic Alignment in Video Diffusion Models via Spatial and SynTactic Guided Attention Refocusing</title>
   <link>https://arxiv.org/abs/2409.15259</link>
   <description>Recent advances in text-to-video (T2V) generation with diffusion models have garnered significant attention. However, they typically perform well in scenes with a single object and motion, struggling in compositional scenarios with multiple objects and distinct motions to accurately reflect the semantic content of text prompts. To address these challenges, we propose \textbf{StarVid}, a plug-and-play, training-free method that improves semantic alignment between multiple subjects, their motions, and text prompts in T2V models. StarVid first leverages the spatial reasoning capabilities of large language models (LLMs) for two-stage motion trajectory planning based on text prompts. Such trajectories serve as spatial priors, guiding a spatial-aware loss to refocus cross-attention (CA) maps into distinctive regions. Furthermore, we propose a syntax-guided contrastive constraint to strengthen the correlation between the CA maps of verbs and their corresponding nouns, enhancing motion-subject binding. Both qualitative and quantitative evaluations demonstrate that the proposed framework significantly outperforms baseline methods, delivering videos of higher quality with improved semantic consistency.</description>
   <guid>oai:arXiv.org:2409.15259v2</guid>
   <category>cs.CV</category>
   <category>cs.AI</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Yuanhang Li, Qi Mao, Lan Chen, Zhen Fang, Lei Tian, Xinyan Xiao, Libiao Jin, Hua Wu</creator>
  </item>
  <item>
   <title>FedBiP: Heterogeneous One-Shot Federated Learning with Personalized Latent Diffusion Models</title>
   <link>https://arxiv.org/abs/2410.04810</link>
   <description>One-Shot Federated Learning (OSFL), a special decentralized machine learning paradigm, has recently gained significant attention. OSFL requires only a single round of client data or model upload, which reduces communication costs and mitigates privacy threats compared to traditional FL. Despite these promising prospects, existing methods face challenges due to client data heterogeneity and limited data quantity when applied to real-world OSFL systems. Recently, Latent Diffusion Models (LDM) have shown remarkable advancements in synthesizing high-quality images through pretraining on large-scale datasets, thereby presenting a potential solution to overcome these issues. However, directly applying pretrained LDM to heterogeneous OSFL results in significant distribution shifts in synthetic data, leading to performance degradation in classification models trained on such data. This issue is particularly pronounced in rare domains, such as medical imaging, which are underrepresented in LDM's pretraining data. To address this challenge, we propose Federated Bi-Level Personalization (FedBiP), which personalizes the pretrained LDM at both instance-level and concept-level. Hereby, FedBiP synthesizes images following the client's local data distribution without compromising the privacy regulations. FedBiP is also the first approach to simultaneously address feature space heterogeneity and client data scarcity in OSFL. Our method is validated through extensive experiments on three OSFL benchmarks with feature space heterogeneity, as well as on challenging medical and satellite image datasets with label heterogeneity. The results demonstrate the effectiveness of FedBiP, which substantially outperforms other OSFL methods.</description>
   <guid>oai:arXiv.org:2410.04810v2</guid>
   <category>cs.LG</category>
   <category>cs.CV</category>
   <category>cs.DC</category>
   <category>cs.MM</category>
   <pubdate>Tue, 04 Mar 2025 00:00:00 -0500</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Haokun Chen, Hang Li, Yao Zhang, Jinhe Bi, Gengyuan Zhang, Yueqi Zhang, Philip Torr, Jindong Gu, Denis Krompass, Volker Tresp</creator>
  </item>
 </channel>
</rss>
