<?xml version="1.0" ?>
<rss>
 <channel>
  <title>arxiv-rss</title>
  <link></link>
  <description></description>
  <docs></docs>
  <language>en-us</language>
  <lastBuildDate>Tue, 02 Sep 2025 03:02:04 </lastBuildDate>
  <managingEditor></managingEditor>
  <pubDate>Tue, 02 Sep 2025 03:02:04 </pubDate>
  <item>
   <title>Decentralized Federated Averaging via Random Walk</title>
   <link>https://arxiv.org/abs/2508.21286</link>
   <description>Federated Learning (FL) is a communication-efficient distributed machine learning method that allows multiple devices to collaboratively train models without sharing raw data. FL can be categorized into centralized and decentralized paradigms. The centralized paradigm relies on a central server to aggregate local models, potentially resulting in single points of failure, communication bottlenecks, and exposure of model parameters. In contrast, the decentralized paradigm, which does not require a central server, provides improved robustness and privacy. The essence of federated learning lies in leveraging multiple local updates for efficient communication. However, this approach may result in slower convergence or even convergence to suboptimal models in the presence of heterogeneous and imbalanced data. To address this challenge, we study decentralized federated averaging via random walk (DFedRW), which replaces multiple local update steps on a single device with random walk updates. Traditional Federated Averaging (FedAvg) and its decentralized versions commonly ignore stragglers, which reduces the amount of training data and introduces sampling bias. Therefore, we allow DFedRW to aggregate partial random walk updates, ensuring that each computation contributes to the model update. To further improve communication efficiency, we also propose a quantized version of DFedRW. We demonstrate that (quantized) DFedRW achieves convergence upper bound of order $\mathcal{O}(\frac{1}{k^{1-q}})$ under convex conditions. Furthermore, we propose a sufficient condition that reveals when quantization balances communication and convergence. Numerical analysis indicates that our proposed algorithms outperform (decentralized) FedAvg in both convergence rate and accuracy, achieving a 38.3\% and 37.5\% increase in test accuracy under high levels of heterogeneities.</description>
   <guid>oai:arXiv.org:2508.21286v1</guid>
   <category>cs.DC</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Changheng Wang, Zhiqing Wei, Lizhe Liu, Qiao Deng, Yingda Wu, Yangyang Niu, Yashan Pang, Zhiyong Feng</creator>
  </item>
  <item>
   <title>A Knowledge Distillation-empowered Adaptive Federated Reinforcement Learning Framework for Multi-Domain IoT Applications Scheduling</title>
   <link>https://arxiv.org/abs/2508.21328</link>
   <description>The rapid proliferation of Internet of Things (IoT) applications across heterogeneous Cloud-Edge-IoT environments presents significant challenges in distributed scheduling optimization. Existing approaches face issues, including fixed neural network architectures that are incompatible with computational heterogeneity, non-Independent and Identically Distributed (non-IID) data distributions across IoT scheduling domains, and insufficient cross-domain collaboration mechanisms. This paper proposes KD-AFRL, a Knowledge Distillation-empowered Adaptive Federated Reinforcement Learning framework that addresses multi-domain IoT application scheduling through three core innovations. First, we develop a resource-aware hybrid architecture generation mechanism that creates dual-zone neural networks enabling heterogeneous devices to participate in collaborative learning while maintaining optimal resource utilization. Second, we propose a privacy-preserving environment-clustered federated learning approach that utilizes differential privacy and K-means clustering to address non-IID challenges and facilitate effective collaboration among compatible domains. Third, we introduce an environment-oriented cross-architecture knowledge distillation mechanism that enables efficient knowledge transfer between heterogeneous models through temperature-regulated soft targets. Comprehensive experiments with real Cloud-Edge-IoT infrastructure demonstrate KD-AFRL's effectiveness using diverse IoT applications. Results show significant improvements over the best baseline, with 21% faster convergence and 15.7%, 10.8%, and 13.9% performance gains in completion time, energy consumption, and weighted cost, respectively. Scalability experiments reveal that KD-AFRL achieves 3-5 times better performance retention compared to existing solutions as the number of domains increases.</description>
   <guid>oai:arXiv.org:2508.21328v1</guid>
   <category>cs.DC</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Zhiyu Wang, Mohammad Goudarzi, Mingming Gong, Rajkumar Buyya</creator>
  </item>
  <item>
   <title>L3Cube-MahaEmotions: A Marathi Emotion Recognition Dataset with Synthetic Annotations using CoTR prompting and Large Language Models</title>
   <link>https://arxiv.org/abs/2506.00863</link>
   <description>Emotion recognition in low-resource languages like Marathi remains challenging due to limited annotated data. We present L3Cube-MahaEmotions, a high-quality Marathi emotion recognition dataset with 11 fine-grained emotion labels. The training data is synthetically annotated using large language models (LLMs), while the validation and test sets are manually labeled to serve as a reliable gold-standard benchmark. Building on the MahaSent dataset, we apply the Chain-of-Translation (CoTR) prompting technique, where Marathi sentences are translated into English and emotion labeled via a single prompt. GPT-4 and Llama3-405B were evaluated, with GPT-4 selected for training data annotation due to superior label quality. We evaluate model performance using standard metrics and explore label aggregation strategies (e.g., Union, Intersection). While GPT-4 predictions outperform fine-tuned BERT models, BERT-based models trained on synthetic labels fail to surpass GPT-4. This highlights both the importance of high-quality human-labeled data and the inherent complexity of emotion recognition. An important finding of this work is that generic LLMs like GPT-4 and Llama3-405B generalize better than fine-tuned BERT for complex low-resource emotion recognition tasks. The dataset and model are shared publicly at https://github.com/l3cube-pune/MarathiNLP</description>
   <guid>oai:arXiv.org:2506.00863v2</guid>
   <category>cs.CL</category>
   <category>cs.LG</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Nidhi Kowtal, Raviraj Joshi</creator>
  </item>
  <item>
   <title>Trust but Verify! A Survey on Verification Design for Test-time Scaling</title>
   <link>https://arxiv.org/abs/2508.16665</link>
   <description>Test-time scaling (TTS) has emerged as a new frontier for scaling the performance of Large Language Models. In test-time scaling, by using more computational resources during inference, LLMs can improve their reasoning process and task performance. Several approaches have emerged for TTS such as distilling reasoning traces from another model or exploring the vast decoding search space by employing a verifier. The verifiers serve as reward models that help score the candidate outputs from the decoding process to diligently explore the vast solution space and select the best outcome. This paradigm commonly termed has emerged as a superior approach owing to parameter free scaling at inference time and high performance gains. The verifiers could be prompt-based, fine-tuned as a discriminative or generative model to verify process paths, outcomes or both. Despite their widespread adoption, there is no detailed collection, clear categorization and discussion of diverse verification approaches and their training mechanisms. In this survey, we cover the diverse approaches in the literature and present a unified view of verifier training, types and their utility in test-time scaling. Our repository can be found at https://github.com/elixir-research-group/Verifierstesttimescaling.github.io.</description>
   <guid>oai:arXiv.org:2508.16665v2</guid>
   <category>cs.CL</category>
   <category>cs.AI</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>V Venktesh, Mandeep Rathee, Avishek Anand</creator>
  </item>
  <item>
   <title>One More Glance with Sharp Eyes: Rethinking Lightweight Captioning as a Practical Visual Specialist</title>
   <link>https://arxiv.org/abs/2508.21451</link>
   <description>Image captioning is fundamental for applications like video instruction systems and exploration robots, yet deploying such models on local devices is challenging due to the high computational demands of multimodal large language models (MLLMs). To address this, we first explore lightweight captioning by implementing a specialist based on a 125M-parameter language model, 56 times smaller than LLaMA-7B, and evaluating its performance on both single-sentence and detailed captioning tasks. Surprisingly, we find that our model can achieve performance comparable to large multimodal generalists, suggesting its potential to serve as a strong visual specialist for on-device applications. While promising, our model also exhibits a limitation: like other MLLMs, it suffers from visual blindness, occasionally resulting in semantic captioning errors. We carry out toy experiments and investigate the underlying causes, where we observe that the problems arise from ineffective attention mechanisms and limited visual representations. To alleviate them, we develop a novel captioning framework, Sharp-Eyed Refinement, which enhances caption quality through improved visual grounding. At its core, our DeepLens extracts detailed visual representations by concentrating on informative regions identified during the initial glance. Our experiments confirm both the advantages of our specialist over prior small captioning models and large generalists and the effectiveness of our framework.</description>
   <guid>oai:arXiv.org:2508.21451v1</guid>
   <category>cs.CV</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Junha Song, Yongsik Jo, So Yeon Min, Quanting Xie, Taehwan Kim, Yonatan Bisk, Jaegul Choo</creator>
  </item>
  <item>
   <title>Federated Fine-tuning of SAM-Med3D for MRI-based Dementia Classification</title>
   <link>https://arxiv.org/abs/2508.21458</link>
   <description>While foundation models (FMs) offer strong potential for AI-based dementia diagnosis, their integration into federated learning (FL) systems remains underexplored. In this benchmarking study, we systematically evaluate the impact of key design choices: classification head architecture, fine-tuning strategy, and aggregation method, on the performance and efficiency of federated FM tuning using brain MRI data. Using a large multi-cohort dataset, we find that the architecture of the classification head substantially influences performance, freezing the FM encoder achieves comparable results to full fine-tuning, and advanced aggregation methods outperform standard federated averaging. Our results offer practical insights for deploying FMs in decentralized clinical settings and highlight trade-offs that should guide future method development.</description>
   <guid>oai:arXiv.org:2508.21458v1</guid>
   <category>cs.CV</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Kaouther Mouheb, Marawan Elbatel, Janne Papma, Geert Jan Biessels, Jurgen Claassen, Huub Middelkoop, Barbara van Munster, Wiesje van der Flier, Inez Ramakers, Stefan Klein, Esther E. Bron</creator>
  </item>
  <item>
   <title>Owen Sampling Accelerates Contribution Estimation in Federated Learning</title>
   <link>https://arxiv.org/abs/2508.21261</link>
   <description>Federated Learning (FL) aggregates information from multiple clients to train a shared global model without exposing raw data. Accurately estimating each client's contribution is essential not just for fair rewards, but for selecting the most useful clients so the global model converges faster. The Shapley value is a principled choice, yet exact computation scales exponentially with the number of clients, making it infeasible for large federations. We propose FedOwen, an efficient framework that uses Owen sampling to approximate Shapley values under the same total evaluation budget as existing methods while keeping the approximation error small. In addition, FedOwen uses an adaptive client selection strategy that balances exploiting high-value clients with exploring under-sampled ones, reducing bias and uncovering rare but informative data. Under a fixed valuation cost, FedOwen achieves up to 23 percent higher final accuracy within the same number of communication rounds compared to state-of-the-art baselines on non-IID benchmarks.</description>
   <guid>oai:arXiv.org:2508.21261v1</guid>
   <category>cs.LG</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>new</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Hossein KhademSohi, Hadi Hemmati, Jiayu Zhou, Steve Drew</creator>
  </item>
  <item>
   <title>Survey of Privacy Threats and Countermeasures in Federated Learning</title>
   <link>https://arxiv.org/abs/2402.00342</link>
   <description>Federated learning is widely considered to be as a privacy-aware learning method because no training data is exchanged directly between clients. Nevertheless, there are threats to privacy in federated learning, and privacy countermeasures have been studied. However, we note that common and unique privacy threats among typical types of federated learning have not been categorized and described in a comprehensive and specific way. In this paper, we describe privacy threats and countermeasures for the typical types of federated learning; horizontal federated learning, vertical federated learning, and transfer federated learning.</description>
   <guid>oai:arXiv.org:2402.00342v2</guid>
   <category>cs.LG</category>
   <category>cs.CR</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Masahiro Hayashitani, Junki Mori, Isamu Teranishi</creator>
  </item>
  <item>
   <title>Federated Diffusion Modeling with Differential Privacy for Tabular Data Synthesis</title>
   <link>https://arxiv.org/abs/2412.16083</link>
   <description>The increasing demand for privacy-preserving data analytics in various domains necessitates solutions for synthetic data generation that rigorously uphold privacy standards. We introduce the DP-FedTabDiff framework, a novel integration of Differential Privacy, Federated Learning and Denoising Diffusion Probabilistic Models designed to generate high-fidelity synthetic tabular data. This framework ensures compliance with privacy regulations while maintaining data utility. We demonstrate the effectiveness of DP-FedTabDiff on multiple real-world mixed-type tabular datasets, achieving significant improvements in privacy guarantees without compromising data quality. Our empirical evaluations reveal the optimal trade-offs between privacy budgets, client configurations, and federated optimization strategies. The results affirm the potential of DP-FedTabDiff to enable secure data sharing and analytics in highly regulated domains, paving the way for further advances in federated learning and privacy-preserving data synthesis.</description>
   <guid>oai:arXiv.org:2412.16083v2</guid>
   <category>cs.LG</category>
   <category>q-fin.ST</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</rights>
   <creator>Timur Sattarov, Marco Schreyer, Damian Borth</creator>
  </item>
  <item>
   <title>Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis</title>
   <link>https://arxiv.org/abs/2504.06235</link>
   <description>Much of federated learning (FL) focuses on settings where local dataset statistics remain the same between training and testing. However, this assumption often does not hold in practice due to distribution shifts, motivating the development of domain generalization (DG) approaches that leverage source domain data to train models capable of generalizing to unseen target domains. In this paper, we are motivated by two major gaps in existing work on FL and DG: (1) the lack of formal mathematical analysis of DG objectives; and (2) DG research in FL being limited to the star-topology architecture. We develop Decentralized Federated Domain Generalization with Style Sharing ($\textit{StyleDDG}$), a decentralized DG algorithm which allows devices in a peer-to-peer network to achieve DG based on sharing style information inferred from their datasets. Additionally, we provide the first systematic approach to analyzing style-based DG training in decentralized networks. We cast existing centralized DG algorithms within our framework, and employ their formalisms to model $\textit{StyleDDG}$. We then obtain analytical conditions under which convergence of $\textit{StyleDDG}$ can be guaranteed. Through experiments on popular DG datasets, we demonstrate that $\textit{StyleDDG}$ can obtain significant improvements in accuracy across target domains with minimal communication overhead compared to baseline decentralized gradient methods.</description>
   <guid>oai:arXiv.org:2504.06235v3</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Shahryar Zehtabi, Dong-Jun Han, Seyyedali Hosseinalipour, Christopher G. Brinton</creator>
  </item>
  <item>
   <title>L3Cube-MahaEmotions: A Marathi Emotion Recognition Dataset with Synthetic Annotations using CoTR prompting and Large Language Models</title>
   <link>https://arxiv.org/abs/2506.00863</link>
   <description>Emotion recognition in low-resource languages like Marathi remains challenging due to limited annotated data. We present L3Cube-MahaEmotions, a high-quality Marathi emotion recognition dataset with 11 fine-grained emotion labels. The training data is synthetically annotated using large language models (LLMs), while the validation and test sets are manually labeled to serve as a reliable gold-standard benchmark. Building on the MahaSent dataset, we apply the Chain-of-Translation (CoTR) prompting technique, where Marathi sentences are translated into English and emotion labeled via a single prompt. GPT-4 and Llama3-405B were evaluated, with GPT-4 selected for training data annotation due to superior label quality. We evaluate model performance using standard metrics and explore label aggregation strategies (e.g., Union, Intersection). While GPT-4 predictions outperform fine-tuned BERT models, BERT-based models trained on synthetic labels fail to surpass GPT-4. This highlights both the importance of high-quality human-labeled data and the inherent complexity of emotion recognition. An important finding of this work is that generic LLMs like GPT-4 and Llama3-405B generalize better than fine-tuned BERT for complex low-resource emotion recognition tasks. The dataset and model are shared publicly at https://github.com/l3cube-pune/MarathiNLP</description>
   <guid>oai:arXiv.org:2506.00863v2</guid>
   <category>cs.CL</category>
   <category>cs.LG</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Nidhi Kowtal, Raviraj Joshi</creator>
  </item>
  <item>
   <title>FL-QDSNNs: Federated Learning with Quantum Dynamic Spiking Neural Networks</title>
   <link>https://arxiv.org/abs/2412.02293</link>
   <description>We present Federated Learning-Quantum Dynamic Spiking Neural Networks (FL-QDSNNs), a privacy-preserving framework that maintains high predictive accuracy on non-IID client data. Its key innovation is a dynamic-threshold spiking mechanism that triggers quantum gates only when local data drift requires added expressiveness, limiting circuit depth and countering the accuracy loss typical of heterogeneous clients. Evaluated on different benchmark datasets, including Iris, where FL-QDSNNs reach 94% accuracy, the approach consistently surpasses state-of-the-art quantum-federated baselines; scaling analyses demonstrate that performance remains high as the federation expands to 25 clients, confirming both computational efficiency and collaboration robustness. By uniting adaptive quantum expressiveness with strict data locality, FL-QDSNNs enable regulation-compliant quantum learning for privacy-sensitive sectors and critical infrastructure.</description>
   <guid>oai:arXiv.org:2412.02293v2</guid>
   <category>quant-ph</category>
   <category>cs.ET</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Nouhaila Innan, Alberto Marchisio, Muhammad Shafique</creator>
  </item>
  <item>
   <title>AI Chatbots as Professional Service Agents: Developing a Professional Identity</title>
   <link>https://arxiv.org/abs/2501.14179</link>
   <description>With the rapid expansion of large language model (LLM) applications, there is an emerging shift in the role of LLM-based AI chatbots from serving merely as general inquiry tools to acting as professional service agents. However, current studies often overlook a critical aspect of professional service agents: the act of communicating in a manner consistent with their professional identities. This is of particular importance in the healthcare sector, where effective communication with patients is essential for achieving professional goals, such as promoting patient well-being by encouraging healthy behaviors. To bridge this gap, we propose LAPI (LLM-based Agent with a Professional Identity), a novel framework for designing professional service agent tailored for medical question-and-answer (Q\&amp;A) services, ensuring alignment with a specific professional identity. Our method includes a theory-guided task planning process that decomposes complex professional tasks into manageable subtasks aligned with professional objectives and a pragmatic entropy method designed to generate professional and ethical responses with low uncertainty. Experiments on various LLMs show that the proposed approach outperforms baseline methods, including few-shot prompting, chain-of-thought prompting, across key metrics such as fluency, naturalness, empathy, patient-centricity, and ROUGE-L scores. Additionally, the ablation study underscores the contribution of each component to the overall effectiveness of the approach.</description>
   <guid>oai:arXiv.org:2501.14179v2</guid>
   <category>cs.HC</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>replace</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>Wenwen Li, Kangwei Shi, Yidong Chai</creator>
  </item>
  <item>
   <title>Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis</title>
   <link>https://arxiv.org/abs/2504.06235</link>
   <description>Much of federated learning (FL) focuses on settings where local dataset statistics remain the same between training and testing. However, this assumption often does not hold in practice due to distribution shifts, motivating the development of domain generalization (DG) approaches that leverage source domain data to train models capable of generalizing to unseen target domains. In this paper, we are motivated by two major gaps in existing work on FL and DG: (1) the lack of formal mathematical analysis of DG objectives; and (2) DG research in FL being limited to the star-topology architecture. We develop Decentralized Federated Domain Generalization with Style Sharing ($\textit{StyleDDG}$), a decentralized DG algorithm which allows devices in a peer-to-peer network to achieve DG based on sharing style information inferred from their datasets. Additionally, we provide the first systematic approach to analyzing style-based DG training in decentralized networks. We cast existing centralized DG algorithms within our framework, and employ their formalisms to model $\textit{StyleDDG}$. We then obtain analytical conditions under which convergence of $\textit{StyleDDG}$ can be guaranteed. Through experiments on popular DG datasets, we demonstrate that $\textit{StyleDDG}$ can obtain significant improvements in accuracy across target domains with minimal communication overhead compared to baseline decentralized gradient methods.</description>
   <guid>oai:arXiv.org:2504.06235v3</guid>
   <category>cs.LG</category>
   <category>cs.AI</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://creativecommons.org/licenses/by/4.0/</rights>
   <creator>Shahryar Zehtabi, Dong-Jun Han, Seyyedali Hosseinalipour, Christopher G. Brinton</creator>
  </item>
  <item>
   <title>Trust but Verify! A Survey on Verification Design for Test-time Scaling</title>
   <link>https://arxiv.org/abs/2508.16665</link>
   <description>Test-time scaling (TTS) has emerged as a new frontier for scaling the performance of Large Language Models. In test-time scaling, by using more computational resources during inference, LLMs can improve their reasoning process and task performance. Several approaches have emerged for TTS such as distilling reasoning traces from another model or exploring the vast decoding search space by employing a verifier. The verifiers serve as reward models that help score the candidate outputs from the decoding process to diligently explore the vast solution space and select the best outcome. This paradigm commonly termed has emerged as a superior approach owing to parameter free scaling at inference time and high performance gains. The verifiers could be prompt-based, fine-tuned as a discriminative or generative model to verify process paths, outcomes or both. Despite their widespread adoption, there is no detailed collection, clear categorization and discussion of diverse verification approaches and their training mechanisms. In this survey, we cover the diverse approaches in the literature and present a unified view of verifier training, types and their utility in test-time scaling. Our repository can be found at https://github.com/elixir-research-group/Verifierstesttimescaling.github.io.</description>
   <guid>oai:arXiv.org:2508.16665v2</guid>
   <category>cs.CL</category>
   <category>cs.AI</category>
   <pubdate>Mon, 01 Sep 2025 00:00:00 -0400</pubdate>
   <announce_type>replace-cross</announce_type>
   <rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</rights>
   <creator>V Venktesh, Mandeep Rathee, Avishek Anand</creator>
  </item>
 </channel>
</rss>
